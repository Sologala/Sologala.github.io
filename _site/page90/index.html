<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta name="keywords"  content="数学, 机器学习, 深度学习">
    <!-- Open Graph -->
    <meta property="og:title" content="DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/page90/">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_271755_rdxzzo2kqwk.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
        }
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>

<body>
    <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
    <input id="nm-switch" type="hidden" value="true">
    <div class="visible">
      <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


<div
    class="g-banner home-banner banner-theme-default"
    data-theme="default"
    style="background: url(https://raw.githubusercontent.com/Sologala/imgdb/master/post/image-20241217235839472.png) no-repeat center center; background-size: cover;"
>
    <h2>Dawson的个人博客</h2>
    <h3>欢迎光临</h3>
</div>

<main class="g-container home-content">
    <div class="article-list">
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/17/unilm.html" title="Unified Language Model Pre-training for Natural Language Understanding and Generation"></a>
                    <img src="https://pic.imgdb.cn/item/611e1b964907e2d39cd309d9.jpg" href="/2021/08/17/unilm.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/17/unilm.html" title="Unified Language Model Pre-training for Natural Language Understanding and Generation"></a>
                    <h2 class="post-title">Unified Language Model Pre-training for Natural Language Understanding and Generation</h2>
                    
                    
                    <p class="post-excerpt">  UniLM：使用BERT实现序列到序列的预训练.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-17">17 Aug 2021</time>
                </footer>
            </article>
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/16/roberta.html" title="RoBERTa: A Robustly Optimized BERT Pretraining Approach"></a>
                    <img src="https://pic.imgdb.cn/item/611f63874907e2d39c6536ca.jpg" href="/2021/08/16/roberta.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/16/roberta.html" title="RoBERTa: A Robustly Optimized BERT Pretraining Approach"></a>
                    <h2 class="post-title">RoBERTa: A Robustly Optimized BERT Pretraining Approach</h2>
                    
                    
                    <p class="post-excerpt">  RoBERTa：鲁棒优化的BERT预训练方法.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-16">16 Aug 2021</time>
                </footer>
            </article>
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/15/efficient.html" title="Efficient Attention: Attention with Linear Complexities"></a>
                    <img src="https://pic.imgdb.cn/item/6117b6f25132923bf88a0953.jpg" href="/2021/08/15/efficient.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/15/efficient.html" title="Efficient Attention: Attention with Linear Complexities"></a>
                    <h2 class="post-title">Efficient Attention: Attention with Linear Complexities</h2>
                    
                    
                    <p class="post-excerpt">  具有线性复杂度的高效自注意力机制.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-15">15 Aug 2021</time>
                </footer>
            </article>
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/14/longformer.html" title="Longformer: The Long-Document Transformer"></a>
                    <img src="https://pic.imgdb.cn/item/61179b1b5132923bf808f170.jpg" href="/2021/08/14/longformer.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/14/longformer.html" title="Longformer: The Long-Document Transformer"></a>
                    <h2 class="post-title">Longformer: The Long-Document Transformer</h2>
                    
                    
                    <p class="post-excerpt">  Longformer: 适用于长文本的Transformer.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-14">14 Aug 2021</time>
                </footer>
            </article>
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/13/linformer.html" title="Linformer: Self-Attention with Linear Complexity"></a>
                    <img src="https://pic.imgdb.cn/item/6114c5e15132923bf88f2f23.jpg" href="/2021/08/13/linformer.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/13/linformer.html" title="Linformer: Self-Attention with Linear Complexity"></a>
                    <h2 class="post-title">Linformer: Self-Attention with Linear Complexity</h2>
                    
                    
                    <p class="post-excerpt">  Linformer: 线性复杂度的自注意力机制.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-13">13 Aug 2021</time>
                </footer>
            </article>
        
            <article class="article-item">
                
                <div class="post-cover">
                    <a class="post-link" href="/2021/08/12/performer.html" title="Rethinking Attention with Performers"></a>
                    <img src="https://pic.imgdb.cn/item/61136ff95132923bf8281465.jpg" href="/2021/08/12/performer.html" alt="">
                </div>
                
                <section class="post-preview">
                    <a class="post-link" href="/2021/08/12/performer.html" title="Rethinking Attention with Performers"></a>
                    <h2 class="post-title">Rethinking Attention with Performers</h2>
                    
                    
                    <p class="post-excerpt">  Performer: 通过随机投影将Attention的复杂度线性化.</p>
                    
                </section>
                <footer class="post-meta">
                    <div class="post-tags">
                        
                            
                            <a href=/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB class="post-tag">论文阅读</a>
                            
                        
                    </div>
                    <time class="post-date" datetime="21-08-12">12 Aug 2021</time>
                </footer>
            </article>
        

        
            <nav class="pagination">
    <input type="hidden" id="total_pages" value="167">
    <input type="hidden" id="current_pages" value="90">
    <input type="hidden" id="base_url" value="/">
    <div class="page-links">
        
            
            <a href="/page89/" class="page-link" title="Previous Page">&laquo;</a>
            
        
        <div id="page-link-container"></div>
        
        <a href="/page91/" class="page-link">&raquo;</a>
        
    </div>
</nav>

        

    </div>

    <aside class="g-sidebar-wrapper">
        <div class="g-sidebar">
            <section class="author-card">
                <div class="avatar">
                    <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
                </div>
                <div class="author-name" rel="author">DawsonWen</div>
                <div class="bio">
                    <p></p>
                </div>
                
                <ul id="sns-links" class="sns-links">
                    
                    <li>
                        <a href="//github.com/Sologala" target="_blank">
                            <i class="iconfont icon-github"></i>
                        </a>
                    </li>
                    
                </ul>
                
            </section>

            
            <section class="tags-card">
                
                    
                    <a href="/tags.html#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" class="tag">机器学习</a>
                
                    
                    <a href="/tags.html#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="tag">深度学习</a>
                
                    
                    <a href="/tags.html#%E6%95%B0%E5%AD%A6" class="tag">数学</a>
                
                    
                    <a href="/tags.html#%E8%8B%B1%E8%AF%AD" class="tag">英语</a>
                
                    
                    <a href="/tags.html#Python" class="tag">Python</a>
                
                    
                    <a href="/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB" class="tag">论文阅读</a>
                
            </section>
            
        </div>

        
        <div class="search-card">
            <input id="search_input" type="text" placeholder="Search..." autocomplete="off">
            <i class="iconfont icon-search"></i>
            <div class="search_result"></div>
        </div>
        

    </aside>

</main>

<!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

    </div>
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
    <script src="/assets/js/prism.js"></script>
    <script src="/assets/js/index.min.js"></script>
</body>
</html>
