<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>度量学习(Metric Learning) - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="度量学习(Metric Learning)">
    <meta name="keywords"  content="深度学习">
    <!-- Open Graph -->
    <meta property="og:title" content="度量学习(Metric Learning) - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2022/11/01/metric.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="post-tag">深度学习</a>
          
        
      </div>
      <h1>度量学习(Metric Learning)</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="22-11-01"><i class="iconfont icon-date"></i>01 Nov 2022</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/63c22967be43e0d30eb7ce66.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>Metric Learning.</p>
</blockquote>

<p><strong>度量学习(Metric Learning)</strong>是指在特定的任务上通过理解样本之间的相似关系，学习一个合适的距离度量函数。传统的度量学习方法通常使用<strong>线性投影</strong>将原始数据的特征空间转化为具有距离信息的新的变换空间，然后在变换空间中应用常用的<a href="https://0809zheng.github.io/2021/02/08/distance.html">距离度量函数</a>衡量样本之间的相似性。</p>

<p>给定数据集\(\{(x_i,y_i)\}\)，深度度量学习通过<strong>共享权重</strong>的深度神经网络$f_{\theta}(\cdot)$把原始样本$x$映射到低维特征空间，并设计合理的<strong>度量损失</strong>使得同类样本在特征空间上的距离比较近，不同类样本之间的距离比较远；从而可以近似实现不同样本的相似度评估，进而应用在人脸识别、行人重识别、图像检索等依赖于样本对匹配的任务中。</p>

<p>本文目录：</p>
<ol>
  <li>正负样本的采样</li>
  <li>网络结构的设计</li>
  <li>损失函数的设计</li>
  <li>使用<strong>PyTorch Metric Learning</strong>实现度量学习</li>
</ol>

<h1 id="1-正负样本的采样">1. 正负样本的采样</h1>

<p>度量学习的目标在于最小化相似样本之间的距离，最大化不相似样本之间的距离。因此对于输入样本$x$ (称为<strong>anchor</strong>样本)，需要合理地选择正样本(相似样本)和负样本(不相似样本)。</p>

<p>在深度度量学习中，负样本对的数量(不同标签的样本)通常远大于正样本对(相同标签的样本)的数量。如果采用简单的随机样本采样策略，即随机选择两个不相似的样本分别作为正负样本，则网络的学习过程可能会受到限制。主要原因是存在低质量的负样本对无法为网络带来有用的信息，因此通过<strong>负样本挖掘(negtive mining)</strong>策略选择负样本。</p>
<ul>
  <li><strong>Easy Negative Mining</strong>：选择显著不同的负样本，可能会产生过于简单的负样本对；</li>
  <li><strong>Hard Negative Mining</strong>：选择由训练数据确定的假阳性样本；</li>
  <li><strong>Semi-Hard Negative Mining</strong>：在给定范围内寻找负样本。</li>
</ul>

<p><img src="https://pic.imgdb.cn/item/63c234cbbe43e0d30ec8f834.jpg" alt="" /></p>

<h1 id="2-网络结构的设计">2. 网络结构的设计</h1>

<p>深度度量学习使用深度神经网络衡量样本对的距离。典型结构是<strong>Siamese</strong>网络，通过共享权重的网络分别接收成对的图像(包括正、负样本)，通过损失函数计算成对图像之间的距离。<strong>Siamese</strong>网络的本质是对同一个网络执行两次前向传播。</p>

<p><img src="https://pic.imgdb.cn/item/63c236fabe43e0d30ecc3de4.jpg" alt="" /></p>

<h1 id="3-损失函数的设计">3. 损失函数的设计</h1>

<ul>
  <li>基于<strong>对(pair)</strong>的度量损失：考虑一个批次样本中样本对之间的关系，最小化正样本对$(x,x^+)$之间的距离，最大化负样本对$(x,x^-)$之间的距离。如<strong>Contrastive Loss</strong>, <strong>Binomial Deviance Loss</strong>, <strong>Triplet Loss</strong>, <strong>Improved Triplet Loss</strong>, <strong>Batch Hard Triplet Loss</strong>, <strong>Hierarchical Triplet Loss</strong>, <strong>Angular Loss</strong>, <strong>Quadruplet Loss</strong>, <strong>N-pair Loss</strong>, <strong>Lift Structured Loss</strong>, <strong>Histogram Loss</strong>, <strong>Ranked List Loss</strong>, <strong>Soft Nearest Neighbor Loss</strong>, <strong>Multi-Similarity Loss</strong>, <strong>Circle Loss</strong>。</li>
  <li>基于<strong>代理(proxy)</strong>的度量损失：为每个类别赋予一个代理样本，拉近每个类别的样本和该类别对应的代理样本之间的距离，拉远与其他类别对应的代理样本之间的距离。如<strong>Magnet Loss</strong>, <strong>Clustering Loss</strong>, <strong>Proxy-NCA</strong>, <strong>ProxyNCA++</strong>, <strong>Proxy-Anchor</strong>。</li>
</ul>

<h2 id="1-基于对的度量损失-pair-based-metric-loss">(1) 基于对的度量损失 Pair-based Metric Loss</h2>

<p><strong>基于对(Pair-based)</strong>的度量损失考虑一个批次样本中样本对之间的关系，最小化正样本对之间的距离，最大化负样本对之间的距离。样本对之间的关系既可以是局部的(考虑少数几个样本)，也可以是非局部的(考虑一个批次的所有样本)。</p>

<h3 id="-contrastive-loss">⚪ <a href="http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf">Contrastive Loss</a></h3>

<p><strong>对比损失(Contrastive Loss)</strong>判断给定的样本对$(x_i,x_j)$之间的正负关系，若为正样本对则使其特征距离接近$0$，若为负样本对则使其特征距离不小于$\epsilon$。</p>

\[\Bbb{I}(y_i=y_j) D[f_{\theta}(x_i),f_{\theta}(x_j)] + \Bbb{I}(y_i\neq y_j) \max(0,\epsilon- D[f_{\theta}(x_i),f_{\theta}(x_j)])\]

<h3 id="-binomial-deviance-loss">⚪ <a href="https://0809zheng.github.io/2022/11/12/binomial.html"><font color="blue">Binomial Deviance Loss</font></a></h3>

<p><strong>二项式偏差损失(Binomial Deviance Loss)</strong>是<strong>对比损失</strong>的软化版本，使用<strong>softplus</strong>函数代替<strong>Hinge loss</strong>：</p>

\[\Bbb{I}(y_i=y_j) \log(1+\exp(\alpha(D[f_{\theta}(x_i),f_{\theta}(x_j)]-\lambda)))  \\ + \Bbb{I}(y_i\neq y_j) \log(1+\exp(\beta(\lambda- D[f_{\theta}(x_i),f_{\theta}(x_j)])))\]

<h3 id="-triplet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/02/triplet.html"><font color="blue">Triplet Loss</font></a></h3>

<p><strong>三元组损失(triplet loss)</strong>为每一个样本$x$选择一个正样本$x^+$和一个负样本$x^-$，使得正样本对之间的距离比负样本对之间的距离小于<strong>margin</strong>值$\epsilon$。</p>

\[\max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x),f_{\theta}(x^-)] + \epsilon)\]

<p><img src="https://pic.imgdb.cn/item/63c50a18be43e0d30eae7254.jpg" alt="" /></p>

<h3 id="-improved-triplet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/17/improved.html"><font color="blue">Improved Triplet Loss</font></a></h3>

<p><strong>Improved Triplet Loss</strong>在<strong>Triplet Loss</strong>的基础上约束正样本对的距离不超过$\beta &lt; \alpha$：</p>

\[\max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x),f_{\theta}(x^-)] + \alpha) \\ + \max(0, D[f_{\theta}(x),f_{\theta}(x^+)] - \beta)\]

<h3 id="-batch-hard-triplet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/16/hard.html"><font color="blue">Batch Hard Triplet Loss</font></a></h3>

<p><strong>Batch Hard Triplet Loss</strong>对每一个样本$x$选择$K$个正样本$x^+_k$和$K$个负样本$x^-_k$，并选用最难的正样本对和负样本对构造损失：</p>

\[\max(0, \mathop{\max}_k D[f_{\theta}(x),f_{\theta}(x^+_k)] - \mathop{\min}_k D[f_{\theta}(x),f_{\theta}(x^-_k)] + \epsilon)\]

<h3 id="-hierarchical-triplet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/10/hierarchical.html"><font color="blue">Hierarchical Triplet Loss</font></a></h3>

<p><strong>分层三元组损失(Hierarchical Triplet Loss)</strong>根据数据集构造分层树，对其进行<strong>Anchor neighbor</strong>采样生成三元组，并根据构造的分层树的类间关系设置<strong>violate margin</strong>:</p>

\[\alpha_z = \beta + d_{H(y_a,y_n)} - S_{y_a}\]

<p><img src="https://pic.imgdb.cn/item/63ca599cbe43e0d30eadec68.jpg" alt="" /></p>

<h3 id="-angular-loss">⚪ <a href="https://0809zheng.github.io/2022/11/07/angular.html"><font color="blue">Angular Loss</font></a></h3>

<p><strong>角度损失(angular loss)</strong>引入了三元组$(x_a,x_p,x_n)$的三阶几何限制，具有尺度不变性和旋转不变性。构造<strong>anchor</strong>样本$x_a$和正样本$x_p$的中心点$x_c=(x_a+x_p)/2$，并以其为圆心作圆；连接$x_n$与$x_c$后作垂线与圆相交于点$x_m$。若角度$n’$减小，则负样本$x_n$沿着$x_cx_n$方向远离样本$x_a$和正样本$x_p$，而样本$x_a$和正样本$x_p$彼此接近。</p>

\[\max(0, D[f_{\theta}(x_a),f_{\theta}(x_p)] -4 \tan^2 \alpha D[f_{\theta}(x_n),f_{\theta}(x_c)||^2])\]

<p><img src="https://pic.imgdb.cn/item/63c7db41be43e0d30e9cde87.jpg" alt="" /></p>

<h3 id="-quadruplet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/08/quadruplet.html"><font color="blue">Quadruplet Loss</font></a></h3>

<p><strong>四元组损失(Quadruplet Loss)</strong>为每一个样本$x$选择一个正样本$x^+$和两个负样本$x^-_1,x^-_2$，使得正样本对之间的距离同时小于负样本对之间的距离和两个负样本之间的距离：</p>

\[\max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x),f_{\theta}(x^-_1)] + \alpha) \\ + \max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x^-_2),f_{\theta}(x^-_1)] + \beta)\]

<p><img src="https://pic.downk.cc/item/5ec23be0c2a9a83be54a3bb6.jpg" alt="" /></p>

<h3 id="-n-pair-loss">⚪ <a href="https://0809zheng.github.io/2022/11/05/npair.html"><font color="blue">N-pair Loss</font></a></h3>

<p><strong>N-pair Loss</strong>把<strong>Triplet</strong>损失扩展到同时比较所有负类样本的距离。对于每一个样本$x$，选择一个正样本$x^+$和所有其他类别的负样本$x_1^-,…,x_{N-1}^-$构造$(N+1)$元组，则<strong>N-pair</strong>损失定义为：</p>

\[- \log\frac{\exp(f_{\theta}(x)^Tf_{\theta}(x^+))}{\exp(f_{\theta}(x)^Tf_{\theta}(x^+))+ \sum_{i=1}^{N-1} \exp(f_{\theta}(x)^Tf_{\theta}(x_i^-))}\]

<p><img src="https://pic.imgdb.cn/item/63c75ba1be43e0d30eab4295.jpg" alt="" /></p>

<h3 id="-lifted-structured-loss">⚪ <a href="https://0809zheng.github.io/2022/11/03/lifted.html"><font color="blue">Lifted Structured Loss</font></a></h3>

<p><strong>Lifted Structured Loss</strong>根据一批样本内的所有样本对之间的关系动态地构建最困难的三元组。对于每一个正样本对$(i,j)$，分别找到距离$i$最近的负样本$k$和距离$j$最近的负样本$l$，选择其中距离较小的负样本$n \in (k,l)$构建三元组$(i,j,n)$。</p>

\[\frac{1}{2| \mathcal{P}|} \sum_{(i,j) \in \mathcal{P}} \max(0,D_{ij} + \max(\mathop{\max}_{(i,k) \in \mathcal{N}} \epsilon-D_{ik},\mathop{\max}_{(j,l) \in \mathcal{N}} \epsilon-D_{jl}))^2\]

<p><img src="https://pic.imgdb.cn/item/63c51218be43e0d30ebd98f7.jpg" alt="" /></p>

<h3 id="-histogram-loss">⚪ <a href="https://0809zheng.github.io/2022/11/04/histogram.html"><font color="blue">Histogram Loss</font></a></h3>

<p><strong>直方图损失(Histogram Loss)</strong>首先估计正样本对和负样本对所对应的两个特征距离分布$p^+(x),p^-(x)$（通过直方图$H^+$和$H^-$近似），然后计算正样本对之间的相似度比负样本对之间的相似度还要小的概率：</p>

\[\int_{-1}^{1}p^-(x) [\int_{-1}^{x}p^+(y)dy] dx ≈ \sum_{r=1}^R (h^-_r \sum_{q=1}^rh_q^+)\]

<p><img src="https://pic.imgdb.cn/item/63c51a55be43e0d30ed19d40.jpg" alt="" /></p>

<h3 id="-ranked-list-loss">⚪ <a href="https://0809zheng.github.io/2022/11/15/ranked.html"><font color="blue">Ranked List Loss</font></a></h3>

<p>给定<strong>anchor</strong>样本$x_i^c$后<strong>Ranked List Loss</strong>基于相似度对其他样本进行排序，然后选择$N_c-1$个距离大于$\alpha-m$的正样本和$N_k$个距离小于$\alpha$的负样本，希望负样本对的距离大于某个阈值$\alpha$，并且正样本对的距离小于$\alpha-m$：</p>

\[\frac{1}{N_c-1} \sum_{j=1}^{N_c-1} \max(0,D[f_{\theta}(x_i),f_{\theta}(x_j)] - (\alpha-m)) \\ + \sum_{j=1}^{N_k} \frac{w_{ij}}{\sum_{j=1}^{N_k}w_{ij}} \max(0,\alpha- D[f_{\theta}(x_i),f_{\theta}(x_j)])\]

<p><img src="https://pic.imgdb.cn/item/63cdec51be43e0d30e214e2c.jpg" alt="" /></p>

<h3 id="-soft-nearest-neighbor-loss">⚪ <a href="https://0809zheng.github.io/2022/11/20/snnl.html"><font color="blue">Soft Nearest Neighbor Loss</font></a></h3>

<p><strong>Soft Nearest Neighbor Loss</strong>用于在表征空间中度量不同类别数据的纠缠度。给定数据集\(\{x_i,y_i\}_{i=1}^N\)，该损失定义为：</p>

\[-\frac{1}{N} \sum_{i=1}^N \log \frac{\sum_{i\neq j,y_i=y_j,j=1,...,N} \exp(-f(x_i,x_j)/ \tau)}{\sum_{i\neq k,k=1,...,N} \exp(-f(x_i,x_k)/ \tau)}\]

<h3 id="-multi-similarity-loss">⚪ <a href="https://0809zheng.github.io/2022/11/18/multisimilarity.html"><font color="blue">Multi-Similarity Loss</font></a></h3>

<p><strong>Multi-Similarity Loss</strong>把基于对的深度度量损失公式化为一种对样本对距离进行加权的通用对加权形式，然后通过自相似性和相对相似性分别为正负样本对赋权。</p>

\[\frac{1}{\alpha} \log(1+\sum_{k \in \mathcal{P}_i} e^{\alpha(D_{ik}+\lambda)}) + \frac{1}{\beta} \log(1+\sum_{k \in \mathcal{N}_i} e^{-\beta(D_{ik}+\lambda)})\]

<p><img src="https://pic.imgdb.cn/item/63cdffc6588a5d166c79e696.jpg" alt="" /></p>

<h3 id="-circle-loss">⚪ <a href="https://0809zheng.github.io/2022/11/19/circleloss.html"><font color="blue">Circle Loss</font></a></h3>

<p><strong>Circle Loss</strong>对欠优化的样本对距离进行重新加权，使得样本对距离远离最优中心的样本对被更多的关注和惩罚。</p>

\[\log(1+ \sum_{j \in \mathcal{N}_i}  \exp(-\gamma\alpha_n^j(D_{ij}+\Delta_n))\sum_{k \in \mathcal{P}_i} \exp(\gamma\alpha_p^k(D_{ik}+\Delta_p)))\]

<p><img src="https://pic.imgdb.cn/item/63cf492e588a5d166c8ebc0c.jpg" alt="" /></p>

<h2 id="2-基于代理的度量损失-proxy-based-metric-loss">(2) 基于代理的度量损失 Proxy-based Metric Loss</h2>

<p><strong>基于代理(Proxy-based)</strong>的度量损失为每个类别赋予一个代理样本，拉近每个类别的样本和该类别的代理样本之间的距离，拉远与其他类别的代理样本之间的距离。代理样本既可以通过给定数据集生成，也可以设置为可学习向量。</p>

<h3 id="-magnet-loss">⚪ <a href="https://0809zheng.github.io/2022/11/06/magnet.html"><font color="blue">Magnet Loss</font></a></h3>

<p><strong>Magnet Loss</strong>检索聚类簇的所有邻域聚类簇，最小化每个聚类簇中的样本与对应样本均值的距离，并最大化与其他簇的样本均值的距离：</p>

\[-\log \frac{e^{-\frac{1}{2\sigma^2}||f_{\theta}(x^c)-\mu_c||_2^2-\alpha}}{\sum_{\mu: c(\mu) \neq c}e^{-\frac{1}{2\sigma^2}||f_{\theta}(x^c)-\mu||_2^2}}\]

<p><img src="https://pic.imgdb.cn/item/63c7b1f1be43e0d30e51f202.jpg" alt="" /></p>

<h3 id="-clustering-loss">⚪ <a href="https://0809zheng.github.io/2022/11/09/clustering.html"><font color="blue">Clustering Loss</font></a></h3>

<p><strong>Clustering Loss</strong>预先为每个类别的样本指定一个聚类中心，要求最佳聚类得分\(\tilde{F}\)比任意其他聚类划分$g(S)$的聚类得分不低于结构化边界$\Delta$：</p>

\[\max(0, \mathop{\max}_{S \subset V,|S| = |Y|} \{ F(X,S;\theta)+\gamma \Delta(g(S),Y) \} - \tilde{F}(X,Y;\theta) )\]

<p><img src="https://pic.imgdb.cn/item/63ca176ebe43e0d30e48fcc8.jpg" alt="" /></p>

<h3 id="-proxy-nca">⚪ <a href="https://0809zheng.github.io/2022/11/11/proxynca.html"><font color="blue">Proxy-NCA</font></a></h3>

<p><strong>Proxy-NCA</strong>为每个类别随机初始化一个代理向量$p$，遍历样本时以邻域成分分析(<strong>NCA</strong>)的形式拉近每个样本$x$和该样本类别$y$对应的代理向量$p_y$之间的距离，增大和其他类别的代理向量$p_z$之间的距离。</p>

\[-\log (\frac{\exp(-D[f_{\theta}(x),p_y])}{\sum_{z \neq y} \exp(-D[f_{\theta}(x),p_z])})\]

<p><img src="https://pic.imgdb.cn/item/63cb521ebe43e0d30e0bea3f.jpg" alt="" /></p>

<h3 id="-proxynca">⚪ <a href="https://0809zheng.github.io/2022/11/14/proxyncapp.html"><font color="blue">ProxyNCA++</font></a></h3>

<p><strong>ProxyNCA++</strong>在<strong>Proxy-NCA</strong>的基础上引入了一些改进，其中对损失函数的改进包括优化代理分配概率和低温缩放。</p>

\[-\log (\frac{\exp(-D[f_{\theta}(x),p_y]/T)}{\sum_{z} \exp(-D[f_{\theta}(x),p_z]/T)})\]

<p><img src="https://pic.imgdb.cn/item/63cbab3bbe43e0d30eb8a8f4.jpg" alt="" /></p>

<h3 id="-proxy-anchor">⚪ <a href="https://0809zheng.github.io/2022/11/13/proxyanchor.html"><font color="blue">Proxy-Anchor</font></a></h3>

<p><strong>Proxy-Anchor</strong>为每个类别随机初始化一个代理向量$p$，遍历每一个代理向量，减少该类别的所有样本与该代理向量的距离，增大其他类别的样本与该代理向量的距离。</p>

\[\frac{1}{|P^+|} \sum_{p \in P^+} \log (1+\sum_{x \in X_p^+}e^{\alpha(D[f_{\theta}(x),p]+\delta)}) \\+ \frac{1}{|P|} \sum_{p \in P} \log (1+\sum_{x \in X_p^-}e^{-\alpha(D[f_{\theta}(x),p]-\delta)})\]

<p><img src="https://pic.imgdb.cn/item/63cba910be43e0d30eb40a03.jpg" alt="" /></p>

<h3 id="-参考文献">⭐ 参考文献</h3>
<ul>
  <li><a href="https://0809zheng.github.io/2022/11/12/binomial.html"><font color="blue">Deep Metric Learning for Practical Person Re-Identifification</font></a>：(arXiv1407)实践的人体重识别中的深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/02/triplet.html"><font color="blue">FaceNet: A Unified Embedding for Face Recognition and Clustering</font></a>：(arXiv1503)FaceNet：通过三元组损失实现人脸识别和聚类的统一嵌入。</li>
  <li><a href="https://0809zheng.github.io/2022/11/03/lifted.html"><font color="blue">Deep Metric Learning via Lifted Structured Feature Embedding</font></a>：(arXiv1511)基于提升结构化特征嵌入的深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/06/magnet.html"><font color="blue">Metric Learning with Adaptive Density Discrimination</font></a>：(arXiv1511)通过自适应密度判别实现度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/17/improved.html"><font color="blue">Person Re-identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function</font></a>：(CVPR2016)通过多通道基于部位的卷积神经网络和改进的三元组损失函数实现人体重识别。</li>
  <li><a href="https://0809zheng.github.io/2022/11/04/histogram.html"><font color="blue">Learning Deep Embeddings with Histogram Loss</font></a>：(arXiv1611)通过直方图损失学习深度嵌入。</li>
  <li><a href="https://0809zheng.github.io/2022/11/05/npair.html"><font color="blue">Improved Deep Metric Learning with Multi-class N-pair Loss Objective</font></a>：(NIPS2016)通过多类别N-pair损失改进深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/09/clustering.html"><font color="blue">Deep Metric Learning via Facility Location</font></a>：(arXiv1612)通过设施位置实现深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/16/hard.html"><font color="blue">In Defense of the Triplet Loss for Person Re-Identification</font></a>：(arXiv1703)为人体重识别任务中的三元组损失辩护。</li>
  <li><a href="https://0809zheng.github.io/2022/11/11/proxynca.html"><font color="blue">No Fuss Distance Metric Learning using Proxies</font></a>：(arXiv1703)使用代理的无融合距离度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/08/quadruplet.html"><font color="blue">Beyond triplet loss: a deep quadruplet network for person re-identification</font></a>：(arXiv1704)用于行人重识别的四元组损失。</li>
  <li><a href="https://0809zheng.github.io/2022/11/07/angular.html"><font color="blue">Deep Metric Learning with Angular Loss</font></a>：(arXiv1708)通过角度损失实现深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/10/hierarchical.html"><font color="blue">Deep Metric Learning with Hierarchical Triplet Loss</font></a>：(arXiv1810)通过层次化三元组损失实现深度度量学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/20/snnl.html"><font color="blue">Analyzing and Improving Representations with the Soft Nearest Neighbor Loss</font></a>：(arXiv1902)通过软最近邻损失分析和改进表示学习。</li>
  <li><a href="https://0809zheng.github.io/2022/11/15/ranked.html"><font color="blue">Ranked List Loss for Deep Metric Learning</font></a>：(arXiv1903)深度度量学习中的排序列表损失。</li>
  <li><a href="https://0809zheng.github.io/2022/11/18/multisimilarity.html"><font color="blue">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning</font></a>：(arXiv1904)深度度量学习的多重相似性损失与通用对加权。</li>
  <li><a href="https://0809zheng.github.io/2022/11/19/circleloss.html"><font color="blue">Circle Loss: A Unified Perspective of Pair Similarity Optimization</font></a>：(arXiv2002)Circle Loss: 成对相似性优化的统一视角。</li>
  <li><a href="https://0809zheng.github.io/2022/11/13/proxyanchor.html"><font color="blue">Proxy Anchor Loss for Deep Metric Learning</font></a>：(arXiv2003)深度度量学习的代理锚点损失。</li>
  <li><a href="https://0809zheng.github.io/2022/11/14/proxyncapp.html"><font color="blue">ProxyNCA++: Revisiting and Revitalizing Proxy Neighborhood Component Analysis</font></a>：(arXiv2004)ProxyNCA++: 回顾和改进深度度量学习中的代理邻域成分分析。</li>
</ul>

<h1 id="4-使用pytorch-metric-learning实现度量学习">4. 使用PyTorch Metric Learning实现度量学习</h1>

<p><a href="https://kevinmusgrave.github.io/pytorch-metric-learning/">PyTorch Metric Learning</a>库是一个为深度度量学习设计的第三方库，安装方式如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">metric</span><span class="o">-</span><span class="n">learning</span>
</code></pre></div></div>

<p>首先初始化一个度量损失函数，以计算训练集中样本对的度量损失：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">losses</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="p">.</span><span class="nc">TripletMarginLoss</span><span class="p">()</span>
</code></pre></div></div>

<p>通常正样本对由共享相同标签的特征嵌入构成，负样本对由具有不同标签的特征嵌入构成；可以通过设置采样策略构造样本对的难例挖掘：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">miners</span>
<span class="n">miner</span> <span class="o">=</span> <span class="n">miners</span><span class="p">.</span><span class="nc">MultiSimilarityMiner</span><span class="p">()</span>
</code></pre></div></div>

<p>在训练过程中传入模型构造的特征嵌入（尺寸为<code class="language-plaintext highlighter-rouge">(batch_size, embedding_size)</code>）以及相应的标签（尺寸为<code class="language-plaintext highlighter-rouge">(batch_size)</code>）：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># your training loop
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">hard_pairs</span> <span class="o">=</span> <span class="nf">miner</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">hard_pairs</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div>

<p>损失函数可通过<code class="language-plaintext highlighter-rouge">distances, reducers, regularizers</code>定义。通过难例挖掘可以找到不同的样本对索引，然后通过定义的距离函数计算样本对之间的距离，并进一步计算损失函数；正则化器则为每个样本计算正则化损失；然后通过衰减器仅保留数值较高的损失项。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pytorch_metric_learning.distances</span> <span class="kn">import</span> <span class="n">CosineSimilarity</span>
<span class="kn">from</span> <span class="n">pytorch_metric_learning.reducers</span> <span class="kn">import</span> <span class="n">ThresholdReducer</span>
<span class="kn">from</span> <span class="n">pytorch_metric_learning.regularizers</span> <span class="kn">import</span> <span class="n">LpRegularizer</span>
<span class="kn">from</span> <span class="n">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">losses</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="p">.</span><span class="nc">TripletMarginLoss</span><span class="p">(</span><span class="n">distance</span> <span class="o">=</span> <span class="nc">CosineSimilarity</span><span class="p">(),</span> 
                                    <span class="n">reducer</span> <span class="o">=</span> <span class="nc">ThresholdReducer</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span> 
                                    <span class="n">embedding_regularizer</span> <span class="o">=</span> <span class="nc">LpRegularizer</span><span class="p">())</span>
</code></pre></div></div>

<p><img src="https://pic.imgdb.cn/item/63c37193be43e0d30ee5aa75.jpg" alt="" /></p>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2022/11/02/triplet.html" class="read-next-link"></a>
        <section>
          <span>FaceNet: A Unified Embedding for Face Recognition and Clustering</span>
          <p>  FaceNet：通过三元组损失实现人脸识别和聚类的统一嵌入.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/63ca7fa8be43e0d30eeb8b3f.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2022/10/31/jigsawclustering.html" class="read-next-link"></a>
          <section>
            <span>Jigsaw Clustering for Unsupervised Visual Representation Learning</span>
            <p>  无监督视觉表示学习的拼图聚类方法.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/63e4a5b14757feff331ec02f.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
