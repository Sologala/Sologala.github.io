<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Longterm Representations for Person Re-Identification Using Radio Signals - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="Learning Longterm Representations for Person Re-Identification Using Radio Signals">
    <meta name="keywords"  content="论文阅读">
    <!-- Open Graph -->
    <meta property="og:title" content="Learning Longterm Representations for Person Re-Identification Using Radio Signals - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2022/06/23/rfreid.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB" class="post-tag">论文阅读</a>
          
        
      </div>
      <h1>Learning Longterm Representations for Person Re-Identification Using Radio Signals</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="22-06-23"><i class="iconfont icon-date"></i>23 Jun 2022</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/62b4040e0947543129944e68.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>RF-ReID：使用射频信号学习目标重识别的长期表示.</p>
</blockquote>

<ul>
  <li>paper：<a href="https://arxiv.org/abs/2004.01091">Learning Longterm Representations for Person Re-Identification Using Radio Signals</a></li>
</ul>

<p>目标重识别（<strong>Re-Identification, ReID</strong>）旨在跨越不同地点和时间识别感兴趣的目标。现有基于光学图像的方法通过提取目标的衣服、头发等外观特征等进行识别，然而这些特征每天都会发生巨大变化，导致无法在较长时间段内实现准确的识别。本文提出一种利用射频信号进行长期目标重识别的方法<strong>RF-ReID</strong>，通过人体反射的射频信号提取更持久的目标识别特征，如身体大小和形状。对于长期的重识别任务(跨越几天和几周的纵向数据集)，<strong>RF-ReID</strong>的表现超过基于光学图像的方法。此外，<strong>RF-ReID</strong>还能够在遮挡和没有照明的环境下工作，且能够保护隐私。</p>

<h1 id="1-研究背景">1. 研究背景</h1>

<p>目标重识别（<strong>Re-Identification, ReID</strong>）旨在使用不同的摄像头在不同的时间和地点匹配感兴趣的人体目标。由于照明、背景、摄像头视角和人体姿态的变化，摄像头中捕捉到的人体目标的视觉外观可能会发生巨大变化，目前已有基于光学图像的<strong>ReID</strong>模型提取出跨摄像头的视图不变的人体外观特征，并在<strong>ReID</strong>数据集上获得了良好的性能。</p>

<p>然而随着时间的推移，人类的视觉外观也会发生巨大的变化。比如人们可能会在不同的日子穿着不同的衣服再次光顾同一家商店，小偷可能会故意更换衣服以误导监控系统。现有的基于光学图像的<strong>ReID</strong>系统本质上依赖于人体目标的外观信息(比如衣服、发型)，这些特征都是短期的，因此模型存在严重的限制。理想的<strong>ReID</strong>系统应该能够提取持续数周或数月的长期识别特征。</p>

<p>射频信号适合捕捉长期的特征。<strong>Wi-Fi</strong>频率范围内的射频信号能够穿过衣服并反射人体，从而提取人体的固有特征，如身体大小或形状，而这些特征在长期时间段内相对稳定。并且射频信号能够在遮挡和照明不良的情况下工作。</p>

<p>直接使用射频信号进行<strong>ReID</strong>任务会面临几个挑战。首先，只使用目标<strong>ID</strong>作为标签来端到端训练模型会导致过拟合问题，因为<strong>ID</strong>标签提供的监督相当薄弱，会使模型倾向于学习一些与环境相关的捷径，比如目标通常所处的位置。其次，与光学图像不同，单个射频信号仅包含来自少数身体部位的反射信息，并忽略身体的其余部分这是由<strong>镜面反射</strong>(<strong>specularity</strong>)效应导致的，因此单个射频信号无法包含足够的全身信息来识别目标。</p>

<p>为了解决过拟合问题，作者提出了一个多任务学习框架和一个环境判别器。除了预测目标的身份外，该框架通过强制模型学习的特征包含足够的信息来预测人体的三维姿态骨骼。环境判别器通过对抗学习强制特征与当前环境无关，与特征提取网络共同训练。为了解决射频信号的镜面反射问题，引入一个分层注意力模块，该模块使用时间维度上的多个射频信号有效地结合人体形状和行走方式的信息。</p>

<p>根据以上思路设计的<strong>RF-ReID</strong>模型可以提取长期可识别的特征，并在遮挡或照明不充足的环境下工作。<strong>RF-ReID</strong>从人体反射的射频信号中提取可识别的特征，并使用提取的特征在时间和空间上进行目标重识别。下图给出了一个目标重识别的结果。基于光学的<strong>ReID</strong>方法将a和b中穿着不同衣服的同一个人误认为是不同的人，而a和c中穿着相同衣服的不同的人误认为是同一个人。相反，<strong>RF-ReID</strong>可以准确地识别a和b是同一个人，而a和c是不同的人。</p>

<p><img src="https://pic.imgdb.cn/item/62b4079b0947543129991ac1.jpg" alt="" /></p>

<h1 id="2-rf-reid模型">2. RF-ReID模型</h1>

<p>使用<strong>FMCW</strong>射频设备收集射频信号，采用水平和垂直的天线阵列，工作频率在$5.4$到$7.2$ GHz之间，可以感应到距离设备最远$12$米的目标。射频信号表示为两个二维热图，其中水平热图是射频信号在平行于地面的平面上的投影，垂直热图是射频信号在垂直于地面的平面上的投影。这些热图可以看作深度图，其中较高的值对应于来自某个位置的信号反射强度较高。系统每秒收集$30$个对射频帧。</p>

<p>下图显示射频信号与视觉数据具有不同的特性。由于人体在工作频率范围内是反射体而不是散射体，当信号的波长大于物体表面的粗糙度时，就会出现镜面反射效应。这种情况下目标就像一面镜子，来自身体各部位的信号可能会反射到传感器上，也可能会反射到远离传感器的地方，具体取决于反射方向。因此每个射频帧只包含来自身体部分区域的反射信息，很难从单个射频帧获得目标全身可识别的信息。</p>

<p><img src="https://pic.imgdb.cn/item/62b436580947543129defe50.jpg" alt="" /></p>

<p><strong>RF-ReID</strong>模型使用射频<strong>tracklet</strong>作为输入。<strong>tracklet</strong>使用边界框描述了水平和垂直热图中人体反射的射频轨迹，每个射频<strong>tracklet</strong>对应一个人体目标。该模型使用一个特征提取网络从<strong>tracklet</strong>中提取特征，然后通过一个可学习的层次注意力模块聚合时间信息以生成特征图。采用多任务学习的方式同时优化身份分类损失、三元组损失和姿态损失。进一步添加一个额外的环境判别器以强制模型学习环境不变的特征，从而推广新环境中。</p>

<p><img src="https://pic.imgdb.cn/item/62b5633a0947543129645863.jpg" alt="" /></p>

<h3 id="1-特征提取网络">(1) 特征提取网络</h3>

<p>由于射频<strong>tracklet</strong>可以有不同的持续时间，首先对每个<strong>tracklet</strong>执行时间采样，从中均匀采样$25$段，每段包含$3$秒（$90$帧）的热图。</p>

<p>特征提取网络首先使用时空卷积从输入射频帧中提取全局特征。然后在特征图中裁剪出轨迹周围的感兴趣区域。最后将裁剪后的特征反馈到子网络中，生成帧级的目标可识别特征。</p>

<h3 id="2-层次注意力模块">(2) 层次注意力模块</h3>

<p>特征提取网络从每个射频段($90$个射频帧)提取相关特征。由于镜面反射，每个射频帧只包含一些身体部位的信息。因此需要在同一个<strong>tracklet</strong>中跨帧聚合特征。<strong>tracklet</strong>中有两种与目标识别相关的信息：形状和行走方式。作者采用一个可学习的两步分层注意力模块来分别聚合每个<strong>tracklet</strong>中的这两种信息。</p>

<p>通过聚合几秒钟射频信号的信息，可以获得人物的粗略形状。这是因为当一个人移动时，可以根据其相对于射频设备的方向接收来自不同身体部位的反射信号。因此在帧级特征上添加第一个注意力块，以聚合每$90$个射频帧($3$秒)内的形状信息。</p>

<p>行走方式只能从更长的时间跨度中推断出来。在射频<strong>tracklet</strong>中可能有许多非步行时间段，这些时间段不能用来推断步行方式。因此使用第二个注意力模块来关注整个<strong>tracklet</strong>中不同片段的特征，并将它们聚合起来，为每个<strong>tracklet</strong>生成一个最终的特征向量。</p>

<h3 id="3-多任务学习">(3) 多任务学习</h3>

<p>为了训练特征提取网络，在<strong>tracklet</strong>中不同片段的特征构造损失函数。首先使用识别损失\(\mathcal{L}_{id}\)，通过两层全连接层的分类网络构造，帮助模型从射频信号中学习目标的可识别特征。其次使用三元组损失\(\mathcal{L}_{triplet}=\max(d_p-d_n+\alpha, 0)\)使得不同目标的特征距离$d_n$足够大，相同目标的特征距离$d_p$足够小。在第二个注意力层上也使用识别分类损失\(\mathcal{L}_{id_t}\)和三元组损失\(\mathcal{L}_{triplet_t}\)。</p>

<p>除了上述损失外，模型也学习从射频信号推断人的姿态骨骼，并添加额外的姿态损失\(\mathcal{L}_{skl}\)。具体地，提取特征提取网络中帧级特征之前两层的中间特征，并将它们输入到生成<strong>3D</strong>人体骨架的姿态估计子网络中。姿态损失是一种二元交叉熵损失，迫使特征包含足够的骨骼生成信息，这有助于推断人的身高和行走方式，还可以作为提取特征的正则化器。</p>

<p><img src="https://pic.imgdb.cn/item/62b5950b0947543129bca8f0.jpg" alt="" /></p>

<h3 id="4-环境判别器">(4) 环境判别器</h3>

<p>射频<strong>tracklet</strong>可能隐含地包含与环境相关的捷径特征，比如一个人比其他人更有可能进入自己的办公室。这将严重损害模型在不同环境中进行泛化的能力。为解决这个问题，需要在训练过程中消除环境相关因素。</p>

<p>若将来自每个射频设备位置的信号视为一个环境，便可以训练环境判别器来预测信号的环境。判别器以对抗的方式进行训练，以便消除依赖于环境的特征。环境判别的交叉熵损失对片段的特征进行操作，将特征提取网络表示为$F$，环境判别器表示为$D$，则判别器损失为：</p>

\[\mathcal{L}_{dis} = -\sum_{c=1}^{M} y_c \log(D(F(x))_c)\]

<p>总目标函数为：</p>

\[\mathop{\min}_{F}  \mathop{\max}_{D}V(F,D) = - \mathcal{L}_{dis} + \mathcal{L}_{id} + \mathcal{L}_{triplet} + \mathcal{L}_{skl}\]

<h1 id="3-实验分析">3. 实验分析</h1>

<h2 id="1-数据集收集">(1) 数据集收集</h2>

<p><strong>RF-ReID</strong>模型在两个数据集上进行评估。<strong>RRD-Campus</strong>数据集是使用部署在校园不同位置的五个射频设备收集的，使用光学相机同步地收集目标的身份标签，共包含$15$天内$100$个目标的信息。数据集中人们多次穿着不同的衣服出现，且不同的人可能会穿相似的衣服。<strong>RRD-Home</strong>数据集最初收集用于评估使用射频信号跟踪帕金森病患者在家中运动的可行性，包括来自$19$个家庭的数据，平均每个家庭数据时长一周。目标的身份标签是通过将可穿戴加速计的运动与射频信号的运动进行比较并手动标记的。</p>

<h3 id="-rrd-campus">⚪ RRD-Campus</h3>

<p><strong>RRD-Campus</strong>数据集是在校园收集的数据集，包含射频信号和同步<strong>RGB</strong>视频数据。视频数据用于提供真值标记，并与基于光学的方法进行比较。通过在校园内的$5$个不同位置部署$5$台射频设备并收集$15$天的数据。使用<strong>NTP</strong>协议同步视频数据和射频信号，最大时差为$10$ ms。</p>

<p>将数据收集系统部署在可能被同一个人再次访问的地方，例如实验室或办公室前面的休息区。收集分辨率为$960\times 720$、每秒$15$帧的视频，用视频给所有反复出现的人贴上标签。数据集总共包含$100$个不同的目标。平均每个目标有$8.63$个射频<strong>tracklet</strong>，每个<strong>tracklet</strong>的跨度超过$11.0$秒。</p>

<p>将<strong>RRD-Campus</strong>数据集分成一个具有$60$个目标的训练集和一个具有其他$40$个目标的测试集。从测试集中的每个目标中随机选择一个样本来构建查询集(<strong>query set</strong>)，并将其余样本分组为库集(<strong>gallery set</strong>)。</p>

<h3 id="-rrd-home">⚪ RRD-Home</h3>

<p><strong>RRD-Home</strong>数据集是一个使用射频信号分析帕金森病的数据集。该数据集是通过在$19$个不同的家庭部署射频设备来收集的，以获取移动人群的射频轨迹，其中每个家庭都包括帕金森病患者和正常人（通常是配偶）。帕金森病患者被要求佩戴加速计来收集加速度数据。收集的数据集包含每个家庭人员的射频轨迹，以及患者的相应加速度数据。</p>

<p>加速度数据用来帮助标记过程。在每个家庭中首先计算每个射频轨迹的位置、移动距离和速度，然后根据运动特性的相似性将患者的加速度数据与相应的射频轨迹相关联。关联成功的射频轨迹标记为患者<strong>ID</strong>，而不匹配的轨迹标记为家中其他人的<strong>ID</strong>。</p>

<p>该数据集包含$19$个不同家庭的$38$个目标。数据覆盖$127$天，平均每户一周。每个目标平均有$165.91$个射频<strong>tracklet</strong>，每个<strong>tracklet</strong>的跨度超过$9.24$秒。</p>

<p><strong>RRD-Home</strong>数据集的训练和测试集分别包含$13$个和$6$个不同的家庭。每个家庭有两个不同的目标。<strong>RRD-Home</strong>数据集还可以与<strong>RRD-Campus</strong>数据集结合起来形成一个更大的数据集<strong>RRD</strong>。</p>

<h2 id="2-评估指标和模型">(2) 评估指标和模型</h2>

<p>在重识别的测试阶段，将查询样本和库样本编码为特征向量。然计算每个查询样本的特征与每个库样本的特征之间的余弦距离，并对距离进行排序，以检索每个查询样本的前$N$个最接近的库样本。根据排名结果计算重识别的标准评估指标：平均精度得分<strong>mAP</strong>和排名$1$和$5$的累积匹配曲线<strong>CMC</strong>。</p>

<p><strong>RF-ReID</strong>模型首先分别在图像数据集<strong>Market1501</strong>和视频数据集<strong>MARS</strong>上分别预训练，然后在训练集上微调。<strong>RRD-Campus</strong>数据集同步收集了光学视频，因此与基于计算机视觉的图像和视频重识别模型分别进行比较。对于基于视频的重识别模型，输入是每个<strong>tracklet</strong>相应的<strong>RGB</strong>视频。对于基于图像的重识别模型，计算视频中每一帧的特征，并对其进行平均以获得样本的特征。</p>

<h2 id="3-评估结果">(3) 评估结果</h2>

<p>作者将<strong>RF-ReID</strong>模型与最先进的基于图像和视频的重识别模型在数据集<strong>RRD-Campus</strong>上进行比较。<strong>RF-ReID</strong>模型的显著改进主要是因为校园里的人在不同的日子穿不同的衣服。传统的基于光学信号的模型侧重于从衣服中提取特征，当同一个人穿着不同的衣服时，该模型会失败。相反，<strong>RF-ReID</strong>模型关注的是一个人的形状和行走方式，这在很长一段时间内都是有效的。</p>

<p>作者还给出了<strong>RF-ReID</strong>模型在<strong>RRD-Home</strong>数据集上的性能。由于隐私原因，此数据集不包括图像或视频，因此无法与基于光学的方法进行比较。结果表明模型在真实家庭场景中也表现良好，而且无需收集个人信息。</p>

<p>结果表明，<strong>RRD-Home</strong>数据集上的表现比<strong>RRD-Campus</strong>差一些。这可能是因为<strong>RRD-Home</strong>数据集提供的的<strong>tacklet</strong>更短（$9.2$秒vs$11$秒）。并且随着药物的影响逐渐减弱，帕金森病患者每天的行走方式可能会有所不同，这表示他们需要服用下一剂药物。</p>

<p><img src="https://pic.imgdb.cn/item/62b5952c0947543129bcd97f.jpg" alt="" /></p>

<p>结合实验结果，<strong>RF-ReID</strong>模型具有以下特点：</p>
<ul>
  <li><strong>RF-ReID</strong>模型适合跨天、数周或更长时间的长期目标重识别任务。</li>
  <li><strong>RF-ReID</strong>模型无需收集或暴露个人信息的数据，实现具有隐私意识的重识别系统。</li>
</ul>

<h2 id="4-消融实验">(4) 消融实验</h2>

<ul>
  <li>姿态估计损失：增加姿态损失可以提高重识别的精度，并且模型本身也能够生成准确的姿态骨骼。</li>
  <li>层次注意力模块：第一个注意力模块聚合短时间内的目标形状信息，第二个注意力模块聚合长期的行走方式信息。如果把其中任意一个模块替换成平均池化，都会降低性能。</li>
  <li>环境判别器：增加环境判别器有助于防止模型生成依赖于环境信息的特征，且大幅度提高性能。</li>
</ul>

<p><img src="https://pic.imgdb.cn/item/62b598720947543129c175e5.jpg" alt="" /></p>

<p>作者使用<strong>t-SNE</strong>展示了<strong>RF-ReID</strong>模型学习的特征空间。图中的每个点对应于从测试集中的轨迹提取的特征向量。测试集共有$5$个环境，根据其环境为每个点着色。该图显示在没有环境判别器的情况下，特征分布与环境密切相关。使用环境判别器后特征与环境成功解耦，分布更加均匀。这进一步表明环境判别器可以帮助模型学习以个人而非环境为中心的识别特征。</p>

<p><img src="https://pic.imgdb.cn/item/62b5997c0947543129c34015.jpg" alt="" /></p>

<h2 id="5-视觉结果">(5) 视觉结果</h2>

<p>作者给出了来自<strong>RRD-Campus</strong>测试集的样本。每个样本对应一个查询样本及其最相似的一个库样本。</p>

<p>结果表明基于光学的重识别方法专注于衣服颜色，比如在图中的第二行，基于光学的方法识别到穿着类似于查询样本的衣服的其他人。而<strong>RF-ReID</strong>模型识别出正确的人，即使他穿着完全不同的衣服。这证明<strong>RF-ReID</strong>模型对衣服变化的鲁棒性。</p>

<p>图中的第三行显示当面临较差的照明或遮挡时，基于光学的方法会失败。而<strong>RF-ReID</strong>模型工作准确，不会受到照明不良的影响，且能够自然穿过墙壁和遮挡。</p>

<p><strong>RF-ReID</strong>模型在某些情况下可能会失败。如最后一行左侧的示例显示人正在骑自行车，这改变了人的行走方式；由于其金属框架，它还会干扰射频反射，导致预测不准确。右侧案例表明当人在滑板上时，此人的行走方式也发生了变化，因此无法正确识别此人。</p>

<p><img src="https://pic.imgdb.cn/item/62b59b480947543129c687f5.jpg" alt="" /></p>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2022/06/24/dalle2.html" class="read-next-link"></a>
        <section>
          <span>Hierarchical Text-Conditional Image Generation with CLIP Latents</span>
          <p>  通过CLIP隐特征实现层次化文本条件图像生成.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/6672c329d9c307b7e9b8288d.png" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2022/06/22/vdm.html" class="read-next-link"></a>
          <section>
            <span>Variational Diffusion Models</span>
            <p>  变分扩散模型.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/6440e5b80d2dde57776840ee.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
