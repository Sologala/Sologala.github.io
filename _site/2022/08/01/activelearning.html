<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>主动学习(Active Learning) - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="主动学习(Active Learning)">
    <meta name="keywords"  content="深度学习">
    <!-- Open Graph -->
    <meta property="og:title" content="主动学习(Active Learning) - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2022/08/01/activelearning.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="post-tag">深度学习</a>
          
        
      </div>
      <h1>主动学习(Active Learning)</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="22-08-01"><i class="iconfont icon-date"></i>01 Aug 2022</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/630b213716f2c2beb1501d64.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>Active Learning.</p>
</blockquote>

<p>深度学习模型通常依赖大量标注数据来提供良好性能，然而数据的标注可能面临成本较高、预算有限、标注困难等问题。<strong>主动学习 (Active Learning)</strong>通过从未标注数据中选择一小部分样本进行标注和训练来降低标注成本；其出发点是并非所有样本对下游任务都是同等重要的，因此仅标注更“重要”的样本能够降低标注成本并最大化模型性能。</p>

<p>给定一个未标注的数据集\(\mathcal{U}\)和样本的标注上限$B$，主动学习旨在从数据集\(\mathcal{U}\)中选择至多包含$B$个样本的子集，使得在该子集上训练的模型比在其他数据上训练时的表现更好。</p>

<p>本文仅讨论适合于深度学习的主动学习方法。深度主动学习面临的困难包括：</p>
<ol>
  <li>深度神经网络的预测结果往往是过度自信的，评估未标注数据的不确定性可能会不可靠。</li>
  <li>深度网络通常会处理大量数据，因此每次需要选择一批样本进而不是单个样本来进行标注。</li>
</ol>

<p>深度主动学习中最常见的场景是基于<strong>池</strong>(<strong>pool-based</strong>)的主动学习，即从大量未标注的数据样本中迭代地选择最“有价值”的数据，直到性能达到指定要求或标注预算耗尽。</p>

<p><img src="https://pic.imgdb.cn/item/630b213716f2c2beb1501d64.jpg" alt="" /></p>

<p>选择最“有价值”的数据的过程被称为<strong>采样策略(sampling strategy)</strong>或<strong>查询策略(query strategy)</strong>，衡量数据“价值”的函数被称为<strong>获取函数(acquisition function)</strong>。</p>

<p>深度主动学习方法可以根据不同的<strong>采样策略</strong>进行分类：</p>
<ul>
  <li><strong>不确定性采样 (uncertainty sampling)</strong>：选择使得模型预测的不确定性最大的样本。不确定性的衡量可以通过机器学习方法(如<strong>entropy</strong>)、<strong>QBC</strong>方法(如<strong>voter entropy</strong>, <strong>consensus entropy</strong>)、贝叶斯神经网络(如<strong>BALD</strong>, <strong>bayes-by-backprop</strong>)、对抗生成(如<strong>GAAL</strong>, <strong>BGADL</strong>)、对抗攻击(如<strong>DFAL</strong>)、损失预测(如<strong>LPL</strong>)、标签预测(如<strong>forgetable event</strong>, <strong>CEAL</strong>)</li>
  <li><strong>多样性采样 (diversity sampling)</strong>：选择更能代表整个数据集分布的样本。多样性的衡量可以通过聚类(如<strong>core-set</strong>, <strong>Cluster-Margin</strong>)、判别学习(如<strong>VAAL</strong>, <strong>CAL</strong>, <strong>DAL</strong>)</li>
  <li><strong>混合策略 (hybrid strategy)</strong>：选择既具有不确定性又具有代表性的样本。样本的不确定性和代表性既可以同时估计(如<strong>exploration-exploitation</strong>, <strong>BatchBALD</strong>, <strong>BADGS</strong>, <strong>Active DPP</strong>, <strong>VAAL</strong>, <strong>MAL</strong>)，也可以分两阶段估计(如<strong>Suggestive Annotation</strong>, <strong>DBAL</strong>)。</li>
</ul>

<h2 id="1-基于不确定性的采样策略-uncertainty-based-sampling-strategy">1. 基于不确定性的采样策略 Uncertainty-based Sampling Strategy</h2>

<p>基于<strong>不确定性(uncertainty)</strong>的采样策略是指在采样时选择具有较高不确定性的数据样本。深度学习中的<a href="https://0809zheng.github.io/2022/08/02/uncertainty.html"><font color="blue">不确定性</font></a>包括偶然不确定性(数据生成过程的固有误差)和认知不确定性(由训练数据的缺乏导致)。</p>

<h3 id="-经典机器学习方法">⚪ 经典机器学习方法</h3>

<p>一些基于不确定性的深度主动学习方法继承于机器学习技术中基于池的主动学习方法(以分类任务为例)。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">方法</th>
      <th style="text-align: center">采样策略</th>
      <th style="text-align: center">获取函数</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">最大熵(<strong>maximum entropy</strong>)</td>
      <td style="text-align: center">选择预测熵最大的样本</td>
      <td style="text-align: center">\(H(y|x)=-\sum_k p(y=k|x) \log p(y=k|x)\)</td>
    </tr>
    <tr>
      <td style="text-align: center">间隔(<strong>margin</strong>)</td>
      <td style="text-align: center">选择预测结果中排名靠前两个类别的预测概率之差最小的样本</td>
      <td style="text-align: center">\(-[p(\hat{y}_1|x)-p(\hat{y}_2|x)]\)</td>
    </tr>
    <tr>
      <td style="text-align: center">最小置信度(<strong>least confidence</strong>)</td>
      <td style="text-align: center">选择预测结果中排名最前类别的预测概率最小的样本</td>
      <td style="text-align: center">\(-p(\hat{y}|x)\)</td>
    </tr>
    <tr>
      <td style="text-align: center">变差比(<strong>Variation Ratio</strong>)</td>
      <td style="text-align: center">与最小置信度类似，衡量置信度的缺乏</td>
      <td style="text-align: center">\(1-p(\hat{y}|x)\)</td>
    </tr>
    <tr>
      <td style="text-align: center">平均标准偏差(<strong>mean standard deviation</strong>)</td>
      <td style="text-align: center">选择所有预测类别的平均标准偏差最大的样本</td>
      <td style="text-align: center">\(\frac{1}{k}\sum_k \sqrt{\text{Var}[p(y=k|x)]}\)</td>
    </tr>
  </tbody>
</table>

<h3 id="-query-by-committee-qbc">⚪ Query-By-Committee (QBC)</h3>

<p>在经典机器学习方法中，也可以训练一系列不同的模型(如设置不同的随机数种子或超参数)，通过给定样本在不同模型之间的输出变化来估计不确定性；这种方法称为<strong>委员会查询(query-by-committee, QBC)</strong>。</p>

<p>若共训练$N$个模型，每个模型的预测结果为$p_1,…,p_N$，则基于<strong>QBC</strong>的获取函数包括：</p>
<ul>
  <li>选民熵(<strong>voter entropy</strong>)：计算标签$y$的票数结果的熵：$H(\frac{\text{vote}(y)}{N})$</li>
  <li>一致熵(<strong>consensus entropy</strong>)：计算平均预测结果的熵：$H(\frac{\sum_n p_n}{N})$</li>
  <li><strong>KL</strong>散度：计算每个模型预测结果与平均预测结果的<strong>KL</strong>散度：$\frac{1}{N}\sum_n KL[p_n||\frac{\sum_n p_n}{N}]$</li>
</ul>

<h3 id="-bayesian-active-learning-by-disagreement-bald">⚪ <a href="https://0809zheng.github.io/2022/08/03/bald.html"><font color="Blue">Bayesian Active Learning by Disagreement (BALD)</font></a></h3>

<p>使用贝叶斯神经网络能够对模型的认知不确定度进行较为准确的估计。贝叶斯神经网络的网络参数是从分布中采样得到的；在进行推断时，通过对参数分布进行积分来集成无穷多的神经网络进行预测。</p>

<p>在实践中采用蒙特卡洛<strong>dropout</strong>进行近似。具体地，在测试时通过多次应用<strong>dropout</strong>，并将结果取平均，便可以实现蒙特卡洛积分近似。<strong>BALD</strong>在此基础上选择模型输出和模型参数的互信息最大的样本：</p>

\[I(y;w | x,D_{train}) ≈ -\sum_c (\frac{1}{T}\sum_t p_c^t)\log (\frac{1}{T}\sum_t p_c^t) +\frac{1}{T}\sum_{t,c} p_c^t\log p_c^t\]

<h3 id="-bayes-by-backprop">⚪ <a href="https://0809zheng.github.io/2022/08/05/bbb.html"><font color="Blue">bayes-by-backprop</font></a></h3>

<p><strong>bayes-by-backprop</strong>方法通过把网络权重建模为一个变分分布$q(w|\theta)$来直接估计认知不确定性。构造变分分布参数$\theta$的损失函数：</p>

\[\mathcal{L}(\theta) =  \log q(w|\theta) - \log p(w)p(D|w)\]

<p>将变分分布$q(w|\theta)$设置为对角高斯分布，通过梯度更新参数$\theta$，进而构造网络权重。认知不确定性可以通过推断时采样不同的模型参数来计算。</p>

<h3 id="-generative-adversarial-active-learning-gaal">⚪ <a href="https://0809zheng.github.io/2022/08/12/gaal.html"><font color="Blue">Generative Adversarial Active Learning (GAAL)</font></a></h3>

<p><strong>GAAL</strong>通过生成对抗网络生成新的样本进行标记和训练，在生成的样本中采样距离决策边界较近的样本(决策边界由支持向量机提供)。</p>

<p><img src="https://pic.imgdb.cn/item/631fe54316f2c2beb1163243.jpg" alt="" /></p>

<h3 id="-bayesian-generative-active-deep-learning-bgadl">⚪ <a href="https://0809zheng.github.io/2022/08/13/bgadl.html"><font color="Blue">Bayesian Generative Active Deep Learning (BGADL)</font></a></h3>

<p><strong>BGADL</strong>通过<strong>BALD</strong>方法选择互信息较大的未标注样本，通过<strong>VAE-ACGAN</strong>模型实现样本生成、样本判别和类别预测。</p>

<p><img src="https://pic.imgdb.cn/item/63202eec16f2c2beb15ef233.jpg" alt="" /></p>

<h3 id="-deep-fool-active-learning-dfal">⚪ <a href="https://0809zheng.github.io/2022/08/11/dfal.html"><font color="Blue">Deep-Fool Active Learning (DFAL)</font></a></h3>

<p><strong>DFAL</strong>利用对抗攻击衡量样本的不确定性。对抗攻击的出发点是寻找最小的扰动以跨越决策边界，因此选择与其对抗样本距离较小的样本，并对原样本和对抗样本采用相同的标签进行标注。</p>

<p><img src="https://pic.imgdb.cn/item/631e9c9b16f2c2beb1f31099.jpg" alt="" /></p>

<h3 id="-loss-prediction-loss-lpl">⚪ <a href="https://0809zheng.github.io/2022/08/04/loss.html"><font color="Blue">Loss Prediction Loss (LPL)</font></a></h3>

<p><strong>损失预测(loss prediction)</strong>的基本思想是预测未标注样本的损失，更高的损失意味着该样本学习更困难、更值得标注。</p>

<p><img src="https://pic.imgdb.cn/item/6318881c16f2c2beb123f731.jpg" alt="" /></p>

<h3 id="-forgetable-event">⚪ <a href="https://0809zheng.github.io/2022/08/10/event.html"><font color="Blue">Forgetable Event</font></a></h3>

<p>遗忘事件记录了样本在训练阶段的预测标签的变化情况。如果模型在训练过程中改变预测结果则表明模型对该样本的不确定性较大，因此在采样时选择标签变化次数较多的可遗忘样本。</p>

<h3 id="-cost-effective-active-learning-ceal">⚪ <a href="https://0809zheng.github.io/2022/08/16/ceal.html"><font color="Blue">Cost-Effective Active Learning (CEAL)</font></a></h3>

<p><strong>CEAL</strong>是一种结合主动学习和自监督学习的框架。一方面通过主动学习选择具有高不确定性的样本进行人工标注，另一方面选择具有较高预测置信度的样本并为它们指定伪标签进行特征学习。</p>

<p><img src="https://pic.imgdb.cn/item/63213e1016f2c2beb15d8e2b.jpg" alt="" /></p>

<h2 id="2-基于多样性的采样策略-diversity-based-sampling-strategy">2. 基于多样性的采样策略 Diversity-based Sampling Strategy</h2>

<p>基于<strong>多样性(diversity)</strong>的采样策略也称为基于<strong>代表性(representive)</strong>的采样策略，是指在采样时选择更能代表整个数据集分布的数据样本。多样性采样在选择数据样本时通常根据样本之间的相似度进行衡量。</p>

<h3 id="-core-set">⚪ <a href="https://0809zheng.github.io/2022/08/08/coreset.html"><font color="Blue">Core-Set</font></a></h3>

<p><strong>core-set</strong>方法是指选择$b$个样本加入训练集后，未标注样本池中的任意样本与其距离最近的已标注样本的距离最小化。实现时常采用贪心算法：每次选择一个与已标注样本集的距离最大的样本进行标注，重复$b$次。</p>

<p><img src="https://pic.imgdb.cn/item/631aa9b416f2c2beb1315394.jpg" alt="" /></p>

<h3 id="-cluster-margin">⚪ <a href="https://0809zheng.github.io/2022/08/18/cm.html"><font color="Blue">Cluster-Margin</font></a></h3>

<p><strong>Cluster-Margin</strong>首先为未标注样本集应用具有平均链接的层次聚集聚类算法生成聚类$C$。然后选择<strong>Margin</strong>得分最低的$k_m$个样本，根据聚类$C$将其划分到不同的聚类簇中。最后采用循环采样的方式从每个簇中采样样本，直至选择$k_t$个样本。</p>

<p><img src="https://pic.imgdb.cn/item/63218c3a16f2c2beb1b1bee2.jpg" alt="" /></p>

<h3 id="-variational-adversarial-active-learning-vaal">⚪ <a href="https://0809zheng.github.io/2021/12/02/VAAL.html"><font color="Blue">Variational Adversarial Active Learning (VAAL)</font></a></h3>

<p><strong>VAAL</strong>使用$\beta$<strong>-VAE</strong>模型将样本嵌入到低维特征空间，并使用一个判别器区分已标注样本和未标注样本的特征。训练完成后，选择判别器预测概率得分最小的一批未标注样本补充到标注池中，因为这些样本与已标注样本具有最小的特征相关性。</p>

<p><img src="https://pic.imgdb.cn/item/61a71dac2ab3f51d91a58f81.jpg" alt="" /></p>

<h3 id="-contrastive-active-learning-cal">⚪ <a href="https://0809zheng.github.io/2022/08/07/cal.html"><font color="Blue">Contrastive Active Learning (CAL)</font></a></h3>

<p><strong>CAL</strong>选择对比得分较高的样本。对比得分是未标注样本$x$与其特征空间中距离最近的$k$个标注样本\(\{x^l\}\)特征之间的平均<strong>KL</strong>散度，即选择与不同标签的样本具有相似特征的新样本。</p>

<p><img src="https://pic.imgdb.cn/item/631a9ebb16f2c2beb12580df.jpg" alt="" /></p>

<h3 id="-discriminative-active-learning-dal">⚪ <a href="https://0809zheng.github.io/2022/08/21/dal.html"><font color="Blue">Discriminative Active Learning (DAL)</font></a></h3>

<p><strong>DAL</strong>把主动学习建模为未标注类别\(\mathcal{U}\)和已标注类别\(\mathcal{L}\)的二分类问题。训练一个二分类器$\Psi$使其能成功区分未标注样本和已标注样本，然后选择未标注类别得分最大的前$K$个样本：</p>

\[\mathop{\arg \max}_{x \in \mathcal{U}} \hat{P} (y=u|\Psi(x))\]

<h2 id="3-混合策略-hybrid-strategy">3. 混合策略 Hybrid Strategy</h2>

<p><strong>混合策略(Hybrid Strategy)</strong>是指在样本的不确定性和多样性之间进行权衡，选择既具有不确定性又具有较强代表性的样本。</p>

<h3 id="-exploration-exploitation">⚪ <a href="https://0809zheng.github.io/2022/08/17/ee.html"><font color="Blue">Exploration-Exploitation</font></a></h3>

<p><strong>exploration-exploitation</strong>采用加权求和的方法同时考虑样本的不确定性得分和多样性得分。<strong>开发(exploitation)</strong>阶段旨在选择具有最大不确定性和最小冗余度的样本；<strong>探索(exploration)</strong>阶段旨在选择距离已标注样本集最远的样本。</p>

<h3 id="-batchbald">⚪ <a href="https://0809zheng.github.io/2022/08/20/batchbald.html"><font color="Blue">BatchBALD</font></a></h3>

<p><strong>BatchBALD</strong>将<strong>BALD</strong>扩展为批量形式，其获取函数为一个批量样本的模型输出与模型参数之间的互信息：</p>

\[\begin{aligned} I(y_1,\cdots,y_B;w | x_1,\cdots,x_B,D_{train}) =&amp; H(y_1,\cdots,y_B|x_1,\cdots,x_B,D_{train}) \\ &amp;- E_{p(w|D_{train})}[H(y_1,\cdots,y_B|x_1,\cdots,x_B,w,D_{train})] \end{aligned}\]

<h3 id="-batch-active-learning-by-diverse-gradient-embedding-badge">⚪ <a href="https://0809zheng.github.io/2022/08/09/badge.html"><font color="Blue">Batch Active learning by Diverse Gradient Embedding (BADGE)</font></a></h3>

<p><strong>BADGE</strong>把样本映射到网络最后一层参数的梯度空间中，同时捕捉模型的不确定性和数据样本的多样性。其中不确定性通过梯度的量级衡量；多样性通过$k$-<strong>means</strong>++算法在梯度空间中选择样本点。</p>

<h3 id="-active-dpp">⚪ <a href="https://0809zheng.github.io/2022/08/19/adpp.html"><font color="Blue">Active DPP</font></a></h3>

<p><strong>Active DPP</strong>使用行列式点过程(<strong>DPP</strong>)建模样本的不确定性和多样性。<strong>DPP</strong>是一类排斥点过程，可以用于生成不同批次的样本。作者使用不确定性<strong>DPP</strong>根据学习模型提供的不确定性得分选择数据样本，并使用探索<strong>DPP</strong>寻找新的决策边界。</p>

<p><img src="https://pic.imgdb.cn/item/632a715e16f2c2beb18d3f69.jpg" alt="" /></p>

<h3 id="-wasserstein-adversarial-active-learning-waal">⚪ <a href="https://0809zheng.github.io/2022/08/22/waal.html"><font color="Blue">Wasserstein Adversarial Active Learning (WAAL)</font></a></h3>

<p><strong>WAAL</strong>采用<strong>Wasserstein</strong>距离将主动学习中的查询过程建模为分布匹配问题，目标函数为：</p>

\[\mathop{\min}_{\hat{B},h} \hat{R}_{\hat{L}∪ \hat{B}}(h) + \mu \mathcal{W}_1(\hat{D},\hat{L}∪ \hat{B})\]

<p>在实践中通过对抗学习来实现，对应的网络由三部分构成：特征提取器$\theta^f$、任务预测器$\theta^h$和分布判别器$\theta^d$；对应的问题可以建模为一个最小-最大优化问题：</p>

\[\mathop{\min}_{\theta^f,\theta^h,\hat{B}} \mathop{\max}_{\theta^d} \hat{R}(\theta^f,\theta^h) + \mu \hat{E}(\theta^f,\theta^d)\]

<h3 id="-minimax-active-learning-mal">⚪ <a href="https://0809zheng.github.io/2022/08/06/mal.html"><font color="Blue">Minimax Active Learning (MAL)</font></a></h3>

<p><strong>MAL</strong>最小化特征编码网络$F$的熵使得具有相似预测标签的样本具有相似的特征；最大化分类器$C$的熵使得预测结果为更均匀的类别分布；判别器$D$则试图有效地区分标记样本和未标记样本。在采样时通过判别器$D$的得分衡量样本的多样性，通过分类器$C$的熵衡量样本的不确定性。</p>

<p><img src="https://pic.imgdb.cn/item/631a8c5816f2c2beb114235b.jpg" alt="" /></p>

<h3 id="-suggestive-annotation">⚪ <a href="https://0809zheng.github.io/2022/08/14/sa.html"><font color="Blue">Suggestive Annotation</font></a></h3>

<p><strong>Suggestive Annotation</strong>首先选择一批具有较高不确定性的样本，再从中选择具有较高代表性的样本进行标注。其中不确定性是利用在标注样本集上训练的集成模型来估计的，而代表性是通过核心集方法进行选择的。</p>

<p><img src="https://pic.imgdb.cn/item/632049d816f2c2beb17cf058.jpg" alt="" /></p>

<h3 id="-diverse-mini-batch-active-learning-dbal">⚪ <a href="https://0809zheng.github.io/2022/08/15/dbal.html"><font color="Blue">Diverse mini-batch Active Learning (DBAL)</font></a></h3>

<p><strong>DBAL</strong>首先选择一批具有较高不确定性的样本，再从中选择具有较高代表性的样本进行标注。其中不确定性是通过加权$k$<strong>-means</strong>算法进行选择的，而代表性是通过$k$<strong>-means</strong>算法进行选择的。</p>

<h2 id="-参考文献">⚪ 参考文献</h2>

<ul>
  <li><a href="https://lilianweng.github.io/posts/2022-02-20-active-learning/">Learning with not Enough Data Part 2: Active Learning</a>：Blog by Lilian Weng.</li>
  <li><a href="https://jacobgil.github.io/deeplearning/activelearning">Overview of Active Learning for Deep Learning</a>：Blog by Jacob Gildenblat.</li>
  <li><a href="https://github.com/SupeRuier/awesome-active-learning#awesome-active-learning">Awesome Active Learning</a>：(github) Hope you can find everything you need about active learning in this repository.</li>
  <li><a href="https://arxiv.org/abs/2203.13450">A Comparative Survey of Deep Active Learning</a>：(arXiv2203)一篇深度主动学习的综述.</li>
  <li><a href="https://0809zheng.github.io/2022/08/05/bbb.html"><font color="Blue">Weight Uncertainty in Neural Networks</font></a>：(arXiv1505)神经网络中的权重不确定性。</li>
  <li><a href="https://0809zheng.github.io/2022/08/16/ceal.html"><font color="Blue">Cost-Effective Active Learning for Deep Image Classification</font></a>：(arXiv1701)CEAL：用于深度图像分类的高性价比主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/12/gaal.html"><font color="Blue">Generative Adversarial Active Learning</font></a>：(arXiv1702)GAAL：生成对抗主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/02/uncertainty.html"><font color="Blue">What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?</font></a>：(arXiv1703)使用贝叶斯深度学习建模深度学习中的不确定性。</li>
  <li><a href="https://0809zheng.github.io/2022/08/03/bald.html"><font color="Blue">Deep Bayesian Active Learning with Image Data</font></a>：(arXiv1703)BALD：贝叶斯不一致主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/14/sa.html"><font color="Blue">Suggestive Annotation: A Deep Active Learning Framework for Biomedical Image Segmentation</font></a>：(arXiv1706)暗示标注：一种用于生物医学图像分割的深度主动学习框架。</li>
  <li><a href="https://0809zheng.github.io/2022/08/08/coreset.html"><font color="Blue">Active Learning for Convolutional Neural Networks: A Core-Set Approach</font></a>：(arXiv1708)基于核心集的主动学习方法。</li>
  <li><a href="https://0809zheng.github.io/2022/08/17/ee.html"><font color="Blue">Deep Similarity-Based Batch Mode Active Learning with Exploration-Exploitation</font></a>：(ICDM2017)通过探索-开发实现基于深度相似性的批处理主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/11/dfal.html"><font color="Blue">Adversarial Active Learning for Deep Networks: a Margin Based Approach</font></a>：(arXiv1802)DFAL：一种基于决策边界的对抗主动学习方法。</li>
  <li><a href="https://0809zheng.github.io/2022/08/15/dbal.html"><font color="Blue">Diverse mini-batch Active Learning</font></a>：(arXiv1901)DBAL：多样性小批量主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/13/bgadl.html"><font color="Blue">Bayesian Generative Active Deep Learning</font></a>：(arXiv1904)BGADL：贝叶斯生成深度主动学习。</li>
  <li><a href="https://0809zheng.github.io/2021/12/02/VAAL.html"><font color="Blue">Variational Adversarial Active Learning</font></a>：(arXiv1904)VAAL: 变分对抗主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/04/loss.html"><font color="Blue">Learning Loss for Active Learning</font></a>：(arXiv1905)主动学习中的损失预测。</li>
  <li><a href="https://0809zheng.github.io/2022/08/20/batchbald.html"><font color="Blue">BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning</font></a>：(arXiv1906)BatchBALD：深度贝叶斯主动学习的高效多样性批量获取。</li>
  <li><a href="https://0809zheng.github.io/2022/08/09/badge.html"><font color="Blue">Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds</font></a>：(arXiv1906)BADGE：基于多样性梯度嵌入的批量主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/19/adpp.html"><font color="Blue">Batch Active Learning Using Determinantal Point Processes</font></a>：(arXiv1906)Active DPP：基于行列式点过程的批量主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/21/dal.html"><font color="Blue">Discriminative Active Learning</font></a>：(arXiv1907)DAL：判别式主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/22/waal.html"><font color="Blue">Deep Active Learning: Unified and Principled Method for Query and Training</font></a>：(arXiv1911)WAAL：使用Wasserstein距离建模主动学习的查询过程。</li>
  <li><a href="https://0809zheng.github.io/2022/08/06/mal.html"><font color="Blue">Minimax Active Learning</font></a>：(arXiv2012)MAL：最小最大主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/10/event.html"><font color="Blue">When Deep Learners Change Their Mind: Learning Dynamics for Active Learning</font></a>：(arXiv2107)基于遗忘事件的主动学习。</li>
  <li><a href="https://0809zheng.github.io/2022/08/18/cm.html"><font color="Blue">Batch Active Learning at Scale</font></a>：(arXiv2107)Cluster-Margin：一种大规模批量主动学习方法。</li>
  <li><a href="https://0809zheng.github.io/2022/08/07/cal.html"><font color="Blue">Active Learning by Acquiring Contrastive Examples</font></a>：(arXiv2109)CAL：对比主动学习。</li>
</ul>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2022/08/02/uncertainty.html" class="read-next-link"></a>
        <section>
          <span>深度学习中的不确定性(Uncertainty)</span>
          <p>  使用贝叶斯深度学习建模深度学习中的不确定性.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/631563d816f2c2beb10dbce6.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2022/07/31/siou.html" class="read-next-link"></a>
          <section>
            <span>SIoU Loss: More Powerful Learning for Bounding Box Regression</span>
            <p>  SIoU Loss：学习更强大的边界框回归.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/6524a77ec458853aef8630b5.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
