<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Comprehensive Guide to Ultralytics YOLOv5 - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="Comprehensive Guide to Ultralytics YOLOv5">
    <meta name="keywords"  content="论文阅读">
    <!-- Open Graph -->
    <meta property="og:title" content="Comprehensive Guide to Ultralytics YOLOv5 - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2022/07/09/yolov5.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB" class="post-tag">论文阅读</a>
          
        
      </div>
      <h1>Comprehensive Guide to Ultralytics YOLOv5</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="22-07-09"><i class="iconfont icon-date"></i>09 Jul 2022</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/65274908c458853aefb02b56.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>YOLOv5：YOLO目标检测模型的第五次迭代.</p>
</blockquote>

<ul>
  <li>Docs：<a href="https://docs.ultralytics.com/yolov5/">Comprehensive Guide to Ultralytics YOLOv5</a></li>
  <li>mmyolo：<a href="https://github.com/open-mmlab/mmyolo/blob/main/docs/zh_cn/recommended_topics/algorithm_descriptions/yolov5_description.md">YOLOv5 原理和实现全解析</a></li>
</ul>

<p><strong>YOLOv5</strong>是一个面向实时工业应用而开源的目标检测算法，其优异性在于开源库的实用和鲁棒性。<strong>YOLOv5</strong>开源库的主要特点为：</p>
<ul>
  <li>友好和完善的部署支持</li>
  <li>算法训练速度极快，在 <strong>300 epoch</strong> 情况下训练时长和大部分算法在 <strong>12 epoch</strong> 的训练时间接近</li>
  <li>框架进行了非常多的特殊情况(<strong>corner case</strong>)优化，功能和文档也比较丰富</li>
</ul>

<p><strong>YOLOv5</strong> 有 <strong>P5</strong> 和 <strong>P6</strong> 两个不同训练输入尺度的模型：<strong>P6</strong> 即为 <strong>1280x1280</strong> 输入的大模型；<strong>P5</strong> 是输入尺寸是 <strong>640x640</strong>的常规模型。本文主要介绍 <strong>P5</strong> 模型结构。</p>

<p><img src="https://pic.imgdb.cn/item/65274bb3c458853aefb0aba4.jpg" alt="" /></p>

<h2 id="1-数据增强模块">1. 数据增强模块</h2>

<p><strong>YOLOv5</strong> 目标检测算法中使用的数据增强比较多，包括：</p>
<ul>
  <li><strong>Mosaic</strong> 马赛克</li>
  <li><strong>RandomAffine</strong> 随机仿射变换</li>
  <li><strong>MixUp</strong></li>
  <li>图像模糊等采用 <strong>Albu</strong> 库实现的变换</li>
  <li><strong>HSV</strong> 颜色空间增强</li>
  <li>随机水平翻转</li>
</ul>

<p>其中 <strong>Mosaic</strong> 数据增强概率为 <strong>1</strong>，表示一定会触发；而对于 <strong>small</strong> 和 <strong>nano</strong> 两个版本的模型不使用 <strong>MixUp</strong>，其他的 <strong>l/m/x</strong> 系列模型则采用了 <strong>0.1</strong> 的概率触发 <strong>MixUp</strong>。</p>

<p>其核心的 <strong>Mosaic + RandomAffine + MixUp</strong> 过程如下：</p>

<p><img src="https://pic.imgdb.cn/item/65274cc8c458853aefb11429.jpg" alt="" /></p>

<h3 id="1mosaic-马赛克">（1）Mosaic 马赛克</h3>

<p><strong>Mosaic</strong> 属于混合类数据增强，因为它在运行时候需要 <strong>4</strong> 张图片拼接，变相的相当于增加了训练的 <strong>batch size</strong>。其运行过程简要概况为：</p>
<ol>
  <li>随机生成拼接后 <strong>4</strong> 张图的交接中心点坐标，此时就相当于确定了 <strong>4</strong> 张拼接图片的交接点</li>
  <li>随机选出另外 <strong>3</strong> 张图片的索引以及读取对应的标注</li>
  <li>对每张图片采用保持宽高比的 <strong>resize</strong> 操作将其缩放到指定大小</li>
  <li>按照上下左右规则，计算每张图片在待输出图片中应该放置的位置，因为图片可能出界故还需要计算裁剪坐标</li>
  <li>利用裁剪坐标将缩放后的图片裁剪，然后贴到前面计算出的位置，其余位置全部补 <strong>114</strong> 像素值</li>
  <li>对每张图片的标注也进行相应处理</li>
</ol>

<p>由于拼接了 <strong>4</strong> 张图，所以输出图片面积会扩大 <strong>4</strong> 倍，从 <strong>640x640</strong> 变成 <strong>1280x1280</strong>，因此要想恢复为 <strong>640x640</strong>， 必须要再接一个 <strong>RandomAffine</strong> 随机仿射变换。</p>

<h3 id="2randomaffine-随机仿射变换">（2）RandomAffine 随机仿射变换</h3>

<p>随机仿射变换有两个目的：</p>
<ol>
  <li>对图片进行随机几何仿射变换</li>
  <li>将 <strong>Mosaic</strong> 输出的扩大 <strong>4</strong> 倍的图片还原为 <strong>640x640</strong> 尺寸</li>
</ol>

<p>随机仿射变换包括平移、旋转、缩放、错切等几何增强操作，同时由于 <strong>Mosaic</strong> 和 <strong>RandomAffine</strong> 属于比较强的增强操作，会引入较大噪声，因此需要对增强后的标注进行处理，过滤规则为：</p>
<ul>
  <li>增强后的 <strong>gt bbox</strong> 宽高要大于 <strong>wh_thr</strong></li>
  <li>增强后的 <strong>gt bbox</strong> 面积和增强前的 <strong>gt bbox</strong> 面积比要大于 <strong>ar_thr</strong>，防止增强太严重</li>
  <li>最大宽高比要小于 <strong>area_thr</strong>，防止宽高比改变太多</li>
  <li>由于旋转后标注框会变大导致不准确，因此目标检测里面很少会使用旋转数据增强。</li>
</ul>

<h3 id="3mixup">（3）MixUp</h3>

<p><strong>MixUp</strong> 和 <strong>Mosaic</strong> 类似也属于混合图片类增强方法。随机选出另外一张图后将两图再随机混合。具体实现方法有多种，常见的做法是要么将 <strong>label</strong> 直接拼接起来，要么将 <strong>label</strong> 也采用 <strong>alpha</strong> 方法混合。</p>

<p><strong>YOLOv5</strong> 实现的 <strong>MixUp</strong> 对 <strong>label</strong> 直接拼接，而图片通过分布采样混合。随机出来的另一张图也需要经过 <strong>Mosaic</strong> 马赛克 + <strong>RandomAffine</strong> 随机仿射变换 的增强后才能混合。</p>

<h2 id="2-网络结构">2. 网络结构</h2>

<p><strong>YOLOv5</strong> 网络结构是标准的 <strong>CSPDarknet</strong> + <strong>PAFPN</strong> + 非解耦 <strong>Head</strong>。</p>

<p><strong>YOLOv5</strong> 网络结构大小由 <strong>deepen_factor</strong> 和 <strong>widen_factor</strong> 两个参数决定。其中 <strong>deepen_factor</strong> 控制网络结构深度，即 <strong>CSPLayer</strong> 中 <strong>DarknetBottleneck</strong> 模块堆叠的数量；<strong>widen_factor</strong> 控制网络结构宽度，即模块输出特征图的通道数。以 <strong>YOLOv5-l</strong> 为例，其 <strong>deepen_factor = widen_factor = 1.0</strong>。</p>

<p><img src="https://pic.imgdb.cn/item/65274af6c458853aefb08988.jpg" alt="" /></p>

<h3 id="1backbone">（1）backbone</h3>

<p><strong>CSPDarknet</strong> 整体结构和 <strong>ResNet</strong> 类似。<strong>P5</strong> 模型共 <strong>5</strong> 层结构，包含 <strong>1</strong> 个 <strong>Stem Layer</strong> 和 <strong>4</strong> 个 <strong>Stage Layer</strong>：</p>
<ul>
  <li><strong>Stem Layer</strong> 是 <strong>1</strong> 个 <strong>6x6</strong> 的 <strong>ConvModule</strong>。</li>
  <li>除了最后一个 <strong>Stage Layer</strong>，其他均由 <strong>1</strong> 个 <strong>ConvModule</strong> 和 <strong>1</strong> 个 <strong>CSPLayer</strong> 组成。其中 <strong>ConvModule</strong> 为 <strong>3x3</strong>的 <strong>Conv2d + BatchNorm + SiLU</strong> 激活函数。<strong>CSPLayer</strong> 由 <strong>3</strong> 个 <strong>ConvModule</strong> + <strong>n</strong> 个 <strong>DarknetBottleneck</strong>(带残差连接) 组成。</li>
  <li>最后一个 <strong>Stage Layer</strong> 在最后增加了 <strong>SPPF</strong> 模块。<strong>SPPF</strong> 模块是将输入串行通过多个 <strong>5x5</strong> 大小的 <strong>MaxPool2d</strong> 层，与 <strong>SPP</strong> 模块效果相同，但速度更快。</li>
  <li><strong>P5</strong> 模型会在 <strong>Stage Layer 2-4</strong> 之后分别输出一个特征图进入 <strong>Neck</strong> 结构。以 <strong>640x640</strong> 输入图片为例，其输出特征为 <strong>(B,256,80,80)</strong>、<strong>(B,512,40,40)</strong> 和 <strong>(B,1024,20,20)</strong>，对应的 <strong>stride</strong> 分别为 <strong>8/16/32</strong>。</li>
  <li><strong>P6</strong> 模型会在 <strong>Stage Layer 2-5</strong> 之后分别输出一个特征图进入 <strong>Neck</strong> 结构。以 <strong>1280x1280</strong> 输入图片为例，其输出特征为 <strong>(B,256,160,160)</strong>、<strong>(B,512,80,80)</strong>、<strong>(B,768,40,40)</strong> 和 <strong>(B,1024,20,20)</strong>，对应的 <strong>stride</strong> 分别为 <strong>8/16/32/64</strong>。</li>
</ul>

<h3 id="2neck">（2）Neck</h3>

<p><strong>YOLOv5 Neck</strong>采用<strong>PAFPN</strong>结构，<strong>Neck</strong> 模块输出的特征图和 <strong>Backbone</strong> 完全一致。即 <strong>P5</strong> 模型为 <strong>(B,256,80,80)</strong>、<strong>(B,512,40,40)</strong> 和 <strong>(B,1024,20,20)</strong>；<strong>P6</strong> 模型为 <strong>(B,256,160,160)</strong>、<strong>(B,512,80,80)</strong>、<strong>(B,768,40,40)</strong> 和 <strong>(B,1024,20,20)</strong>。</p>

<h3 id="3head">（3）Head</h3>

<p><strong>YOLOv5 Head</strong> 结构和 <strong>YOLOv3</strong> 完全一样，为非解耦<strong>Head</strong>。<strong>Head</strong> 模块只包括 <strong>3</strong> 个不共享权重的卷积，用于将输入特征图进行变换。由于 <strong>YOLOv5</strong> 是非解耦输出，即分类和 <strong>bbox</strong> 检测等都是在同一个卷积的不同通道中完成。以 <strong>COCO 80</strong> 类为例：</p>
<ul>
  <li><strong>P5</strong> 模型在输入为 <strong>640x640</strong> 分辨率情况下，其 <strong>Head</strong> 模块输出的 <strong>shape</strong> 分别为 <strong>(B, 3x(4+1+80),80,80)</strong>, <strong>(B, 3x(4+1+80),40,40)</strong> 和 <strong>(B, 3x(4+1+80),20,20)</strong>。</li>
  <li><strong>P6</strong> 模型在输入为 <strong>1280x1280</strong> 分辨率情况下，其 <strong>Head</strong> 模块输出的 <strong>shape</strong> 分别为 <strong>(B, 3x(4+1+80),160,160)</strong>, <strong>(B, 3x(4+1+80),80,80)</strong>, <strong>(B, 3x(4+1+80),40,40)</strong> 和 <strong>(B, 3x(4+1+80),20,20)</strong>。</li>
  <li>其中 <strong>3</strong> 表示 <strong>3</strong> 个 <strong>anchor</strong>，<strong>4</strong> 表示 <strong>bbox</strong> 预测分支，<strong>1</strong> 表示 <strong>obj</strong> 预测分支，<strong>80</strong> 表示 <strong>COCO</strong> 数据集类别预测分支。</li>
</ul>

<h2 id="3-正负样本匹配策略">3. 正负样本匹配策略</h2>

<p>正负样本匹配策略的核心是确定预测特征图的所有位置中哪些位置应该是正样本，哪些是负样本，甚至有些是忽略样本。 匹配策略是目标检测算法的核心，一个好的匹配策略可以显著提升算法性能。</p>

<p><strong>YOLOV5</strong> 的匹配策略简单总结为：采用了 <strong>anchor</strong> 和 <strong>gt_bbox</strong> 的形状匹配度作为划分规则，同时引入跨邻域网格策略来增加正样本。 其主要包括如下两个核心步骤：</p>
<ul>
  <li>对于任何一个输出层，抛弃了常用的基于 <strong>Max IoU</strong> 匹配的规则，而是直接采用形状规则匹配，也就是该 <strong>GT Bbox</strong> 和当前层的 <strong>Anchor</strong> 计算宽高比，如果宽高比例大于设定阈值，则说明该 <strong>GT Bbox</strong> 和 <strong>Anchor</strong> 匹配度不够，将该 <strong>GT Bbox</strong> 暂时丢掉，在该层预测中该 <strong>GT Bbox</strong> 对应的网格内的预测位置认为是负样本</li>
  <li>对于匹配上的 <strong>GT Bbox</strong>，计算其落在哪个网格内，同时利用四舍五入规则，额外找出最近的两个网格，将这三个网格都认为是负责预测该 <strong>GT Bbox</strong> 的，可以粗略估计正样本数相比之前的 <strong>YOLO</strong> 系列，至少增加了三倍。</li>
</ul>

<h3 id="1anchor设置">（1）Anchor设置</h3>

<p><strong>YOLOv5</strong> 是 <strong>Anchor-based</strong> 的目标检测算法，其 <strong>Anchor size</strong> 的获取方式与 <strong>YOLOv3</strong> 类似，也是使用聚类获得，其不同之处在于聚类使用的标准不再是基于 <strong>IoU</strong> 的，而是使用形状上的宽高比作为聚类准则(即 <strong>shape-match</strong>)。</p>

<p>默认 <strong>Anchor size</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anchors</span> <span class="o">=</span> <span class="p">[[(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">23</span><span class="p">)],</span> <span class="p">[(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">61</span><span class="p">),</span> <span class="p">(</span><span class="mi">62</span><span class="p">,</span> <span class="mi">45</span><span class="p">),</span> <span class="p">(</span><span class="mi">59</span><span class="p">,</span> <span class="mi">119</span><span class="p">)],</span>
           <span class="p">[(</span><span class="mi">116</span><span class="p">,</span> <span class="mi">90</span><span class="p">),</span> <span class="p">(</span><span class="mi">156</span><span class="p">,</span> <span class="mi">198</span><span class="p">),</span> <span class="p">(</span><span class="mi">373</span><span class="p">,</span> <span class="mi">326</span><span class="p">)]]</span>
</code></pre></div></div>

<h3 id="2bbox-编解码过程">（2）Bbox 编解码过程</h3>

<p>在 <strong>Anchor-based</strong> 算法中，预测框通常会基于 <strong>Anchor</strong> 进行变换，然后预测变换量，这对应 <strong>GT Bbox</strong> 编码过程，而在预测后需要进行 <strong>Pred Bbox</strong> 解码，还原为真实尺度的 <strong>Bbox</strong>，这对应 <strong>Pred Bbox</strong> 解码过程。</p>

<p>在 <strong>YOLOv3</strong> 中，回归公式为：</p>

\[\begin{aligned}
b_x&amp;=\sigma(t_x)+c_x  \\
b_y&amp;=\sigma(t_y)+c_y  \\
b_w&amp;=a_w\cdot e^{t_w} \\
b_h&amp;=a_h\cdot e^{t_h} \\
\end{aligned}\]

<p>而在 <strong>YOLOv5</strong> 中，回归公式为：</p>

\[\begin{aligned}
b_x&amp;=(2\cdot\sigma(t_x)-0.5)+c_x   \\
b_y&amp;=(2\cdot\sigma(t_y)-0.5)+c_y   \\
b_w&amp;=a_w\cdot(2\cdot\sigma(t_w))^2   \\
b_h&amp;=a_h\cdot(2\cdot\sigma(t_h))^2
\end{aligned}\]

<p>改进之处主要有以下两点：</p>
<ul>
  <li>中心点坐标范围从 $(0, 1)$ 调整至 $(-0.5, 1.5)$</li>
  <li>宽高范围从$(0，+\infty)$ 调整至 $(0，4a_{wh})$</li>
</ul>

<p>这个改进具有以下好处：</p>
<ul>
  <li>新的中心点设置能更好的预测到 <strong>0</strong> 和 <strong>1</strong>。这有助于更精准回归出 <strong>box</strong> 坐标。</li>
  <li>宽高回归公式中 $exp(x)$ 是无界的，这会导致梯度失去控制，造成训练不稳定。<strong>YOLOv5</strong> 中改进后的宽高回归公式优化了此问题。</li>
</ul>

<h3 id="3匹配策略">（3）匹配策略</h3>

<p><strong>YOLOv5</strong>的正样本匹配策略采用“比例”比较，即将 <strong>GT Bbox</strong> 的 <strong>WH</strong> 与 <strong>Anchor</strong> 的 <strong>WH</strong> 分别进行比例比较，要求最大比例$r^{max}$不超过给定阈值才算成功匹配。</p>

\[\begin{aligned}
r_w &amp;= w_{gt} / w_{pt}    \\
r_h &amp; = h_{gt} / h_{pt}    \\
r_w^{max}&amp;=\max(r_w, 1/r_w)  \\
r_h^{max}&amp;=\max(r_h, 1/r_h)  \\
r^{max}&amp;=\max(r_w^{max}, r_h^{max})   \\
\end{aligned}\]

<p><img src="https://pic.imgdb.cn/item/65279bd9c458853aefc78cb4.jpg" alt="" /></p>

<p><strong>GT Bbox</strong>成功匹配之后，会将其相近的两个邻域位置也设置为正样本：</p>

<p><img src="https://pic.imgdb.cn/item/65279db8c458853aefc84e12.jpg" alt="" /></p>

<p><strong>YOLOv5</strong> 的 <strong>Assign</strong> 方式带来了以下改进：</p>
<ul>
  <li>一个 <strong>GT Bbox</strong> 能够匹配多个 <strong>Anchor</strong></li>
  <li>一个 <strong>GT Bbox</strong> 和一个<strong>Anchor</strong> 匹配时，能分配 <strong>1-3</strong> 个正样本</li>
  <li>以上策略能适度缓解目标检测中常见的正负样本不均衡问题。</li>
</ul>

<h2 id="4-训练策略">4. 训练策略</h2>

<h3 id="1损失函数">（1）损失函数</h3>

<p><strong>YOLOv5</strong> 中总共包含 <strong>3</strong> 个 <strong>Loss</strong>，分别为：</p>
<ul>
  <li><strong>Classes loss</strong>：使用的是 <strong>BCE loss</strong></li>
  <li><strong>Objectness loss</strong>：使用的是 <strong>BCE loss</strong></li>
  <li><strong>Location loss</strong>：使用的是 <strong>CIoU loss</strong></li>
</ul>

<p>三个 <strong>loss</strong> 按照一定比例汇总：</p>

\[Loss=\lambda_1L_{cls}+\lambda_2L_{obj}+\lambda_3L_{loc}\]

<p><strong>P3</strong>、<strong>P4</strong>、<strong>P5</strong> 层对应的 <strong>Objectness loss</strong> 按照不同权重进行相加，默认的设置是：</p>

\[L_{obj}=4.0\cdot L_{obj}^{small}+1.0\cdot L_{obj}^{medium}+0.4\cdot L_{obj}^{large}\]

<h3 id="2优化策略">（2）优化策略</h3>

<p>将优化参数分成 <strong>Conv/Bias/BN</strong> 三组，在 <strong>WarmUp</strong> 阶段，不同组采用不同的学习率以及 <strong>momentum</strong> 更新曲线。 同时在 <strong>WarmUp</strong> 阶段采用的是 <strong>iter-based</strong> 更新策略，而在非 <strong>WarmUp</strong> 阶段则变成 <strong>epoch-based</strong> 更新策略。</p>

<p>针对不同的 <strong>batch size</strong> 采用了不同的 <strong>weight decay</strong> 策略，具体来说为：</p>
<ul>
  <li>当训练 <strong>batch size</strong> $&lt;= 64$ 时，<strong>weight decay</strong> 不变</li>
  <li>当训练 <strong>batch size</strong> $&gt; 64$ 时，<strong>weight decay</strong> 会根据总 <strong>batch size</strong> 进行线性缩放</li>
</ul>

<p>为了最大化不同 <strong>batch size</strong> 情况下的性能，设置总 <strong>batch size</strong> 小于 <strong>64</strong> 时候会自动开启梯度累加功能。</p>

<h3 id="3推理过程">（3）推理过程</h3>

<p><strong>YOLOv5</strong> 输出特征图尺度为 <strong>80x80</strong>、<strong>40x40</strong> 和 <strong>20x20</strong> 的三个特征图，每个位置共 <strong>3</strong> 个 <strong>anchor</strong>，因此输出特征图通道为 $3\times(5+80)=255$。 <strong>YOLOv5</strong> 是非解耦输出头，因此首先提前将其进行解耦，分成了类别预测分支、<strong>bbox</strong> 预测分支和 <strong>obj</strong> 预测分支。</p>

<p><strong>YOLOv5</strong>的推理过程如下：</p>
<ol>
  <li>将三个不同尺度的类别预测分支、<strong>bbox</strong> 预测分支和 <strong>obj</strong> 预测分支进行拼接，并进行维度变换。为了后续方便处理，会将原先的通道维度置换到最后，类别预测分支、<strong>bbox</strong> 预测分支和 <strong>obj</strong> 预测分支的形状分别为 <strong>(b, 3x80x80+3x40x40+3x20x20, 80)=(b,25200,80)，(b,25200,4)，(b,25200,1)</strong>。</li>
  <li>分类预测分支和 <strong>obj</strong> 分支需要进行 <strong>sigmoid</strong> 计算，而 <strong>bbox</strong> 预测分支需要进行解码，还原为真实的原图解码后 <strong>xyxy</strong> 格式。</li>
  <li>遍历 <strong>batch</strong> 中的每张图，然后用 <strong>score_thr</strong> 对类别预测分值进行阈值过滤，去掉低于 <strong>score_thr</strong> 的预测结果</li>
  <li>将 <strong>obj</strong> 预测分值和过滤后的类别预测分值相乘，然后依然采用 <strong>score_thr</strong> 进行阈值过滤，确保过滤后的检测框数目不会多于 <strong>nms_pre</strong>。</li>
  <li>基于前处理过程，将剩下的检测框还原到网络输出前的原图尺度，然后进行 <strong>nms</strong> 即可。最终输出的检测框不能多于 <strong>max_per_img</strong>。</li>
</ol>

<p><img src="https://pic.imgdb.cn/item/6527a34ec458853aefc9c491.jpg" alt="" /></p>

<h3 id="4batch-shape-策略">（4）batch shape 策略</h3>

<p>为了加速验证集的推理过程，作者提出了 <strong>batch shape</strong> 策略，其核心原则是：确保在 <strong>batch</strong> 推理过程中同一个 <strong>batch</strong> 内的图片 <strong>pad</strong> 像素最少，不要求整个验证过程中所有 <strong>batch</strong> 的图片尺度一样。</p>

<p>其大概流程是：将整个测试或者验证数据的宽高比进行排序，然后依据 <strong>batch</strong> 设置将排序后的图片组成一个 <strong>batch</strong>， 同时计算这个 <strong>batch</strong> 内最佳的 <strong>batch shape</strong>，防止 <strong>pad</strong> 像素过多。最佳 <strong>batch shape</strong> 计算原则为在保持宽高比的情况下进行 <strong>pad</strong>，不追求正方形图片输出。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">image_shapes</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">data_info</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">:</span>
      <span class="n">image_shapes</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">data_info</span><span class="p">[</span><span class="sh">'</span><span class="s">width</span><span class="sh">'</span><span class="p">],</span> <span class="n">data_info</span><span class="p">[</span><span class="sh">'</span><span class="s">height</span><span class="sh">'</span><span class="p">]))</span>

  <span class="n">image_shapes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image_shapes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

  <span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">image_shapes</span><span class="p">)</span>  <span class="c1"># number of images
</span>  <span class="n">batch_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span>
      <span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>  <span class="c1"># batch index
</span>  <span class="n">number_of_batches</span> <span class="o">=</span> <span class="n">batch_index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># number of batches
</span>
  <span class="n">aspect_ratio</span> <span class="o">=</span> <span class="n">image_shapes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">image_shapes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># aspect ratio
</span>  <span class="n">irect</span> <span class="o">=</span> <span class="n">aspect_ratio</span><span class="p">.</span><span class="nf">argsort</span><span class="p">()</span>

  <span class="n">data_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">irect</span><span class="p">]</span>

  <span class="n">aspect_ratio</span> <span class="o">=</span> <span class="n">aspect_ratio</span><span class="p">[</span><span class="n">irect</span><span class="p">]</span>
  <span class="c1"># Set training image shapes
</span>  <span class="n">shapes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">number_of_batches</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">number_of_batches</span><span class="p">):</span>
      <span class="n">aspect_ratio_index</span> <span class="o">=</span> <span class="n">aspect_ratio</span><span class="p">[</span><span class="n">batch_index</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
      <span class="n">min_index</span><span class="p">,</span> <span class="n">max_index</span> <span class="o">=</span> <span class="n">aspect_ratio_index</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span>
      <span class="p">),</span> <span class="n">aspect_ratio_index</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">max_index</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_index</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">elif</span> <span class="n">min_index</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">min_index</span><span class="p">]</span>

  <span class="n">batch_shapes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ceil</span><span class="p">(</span>
      <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">shapes</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">img_size</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">size_divisor</span> <span class="o">+</span>
      <span class="n">self</span><span class="p">.</span><span class="n">pad</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">size_divisor</span>

  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data_info</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data_list</span><span class="p">):</span>
      <span class="n">data_info</span><span class="p">[</span><span class="sh">'</span><span class="s">batch_shape</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_shapes</span><span class="p">[</span><span class="n">batch_index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</code></pre></div></div>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2022/07/10/yolov7.html" class="read-next-link"></a>
        <section>
          <span>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</span>
          <p>  YOLOv7：实时目标检测器的可训练技巧.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/668cf372d9c307b7e9e9e258.png" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2022/07/08/vitpose.html" class="read-next-link"></a>
          <section>
            <span>ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation</span>
            <p>  ViTPose：用于人体姿态估计的简单视觉Transformer基线.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/64a388b91ddac507cc5bc6de.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
