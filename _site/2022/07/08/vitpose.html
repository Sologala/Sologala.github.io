<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation">
    <meta name="keywords"  content="论文阅读">
    <!-- Open Graph -->
    <meta property="og:title" content="ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2022/07/08/vitpose.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB" class="post-tag">论文阅读</a>
          
        
      </div>
      <h1>ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="22-07-08"><i class="iconfont icon-date"></i>08 Jul 2022</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/64a388b91ddac507cc5bc6de.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>ViTPose：用于人体姿态估计的简单视觉Transformer基线.</p>
</blockquote>

<ul>
  <li>paper：<a href="https://arxiv.org/abs/2204.12484">ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation</a></li>
</ul>

<p><strong>Vison Transformer</strong>在视觉识别任务中效果优秀，但还没有工作在姿态估计任务上验证这种结构的有效性。本文提出了用于姿态估计的<strong>Transformer</strong>网络<strong>ViTPose</strong>，使用<strong>ViT</strong>结构作为<strong>Backbone</strong>，结合一个轻量级的<strong>Decoder</strong>，在<strong>MS COCO</strong>关键点估计<strong>bechmark</strong>上达到<strong>SOTA</strong>。</p>

<h1 id="1-vitpose的结构">1. ViTPose的结构</h1>

<p><strong>ViTPose</strong>的网络结构设计比较简单，整体采用<a href="https://0809zheng.github.io/2020/12/30/vit.html"><font color="Blue">ViT</font></a> <strong>backbone + decoder</strong>的形式。</p>

<p><img src="https://pic.imgdb.cn/item/64a38a991ddac507cc5f767b.jpg" alt="" /></p>

<p><strong>ViT Backbone</strong>分为<strong>patch embedding</strong>和多个<strong>transformer</strong>模块。<strong>patch embedding</strong>将图像分为$d\times d$的<strong>patch</strong>块。而每个<strong>transformer</strong>层包含 <strong>multi-head self-attention(MHSA)</strong> 与 <strong>feed-forward network (FFN)</strong> 模块。多个<strong>transformer</strong>层堆叠，构成了<strong>backbone</strong>。</p>

<p><strong>backbone</strong>根据计算量大小可以分别选用<strong>Vit-B, ViT-L，ViT-H</strong>以及<strong>ViTAE-G</strong>。</p>

<p><img src="https://pic.imgdb.cn/item/64a38b991ddac507cc61b362.jpg" alt="" /></p>

<p>在<strong>decoder</strong>的选取上，作者选择了两种结构进行了对比:</p>
<ol>
  <li>经典<strong>Decoder</strong>结构，两个<strong>Deconv(+BN+ReLU) + 1x1conv</strong>，每个<strong>deconv</strong>上采样<strong>2</strong>倍，最终输出<strong>feature map</strong>大小为输入的$1/4$倍;</li>
  <li>简单<strong>Decoder</strong>结构，双线性差值上采样$4$倍，然后是<strong>ReLU+3x3conv</strong>。</li>
</ol>

<p>方案<strong>1</strong>非线性更高，因此在<strong>CNN</strong>的结构中使用比较多。<strong>ResNet</strong>系列在方案<strong>1</strong>上的结果远高于方案<strong>2</strong>，说明<strong>CNN</strong>结构的学习能力需要强有力的<strong>decoder</strong>来进一步加强。由于<strong>Transformer</strong>强大的学习能力，方案<strong>2</strong>这样的的简单<strong>decoder</strong>也能达到很高的精度。</p>

<p><img src="https://pic.imgdb.cn/item/64a38d051ddac507cc64e956.jpg" alt="" /></p>

<p>实验采用姿态估计中<strong>Top-Down</strong>的方案，即先用一个检测器检测出单个人体框，然后用<strong>ViTPose</strong>对人体框进行姿态估计。第一步的检测器在<strong>COCO</strong>的<strong>val</strong>集上用的是<strong>SimpleBaseline</strong>，而在最后的<strong>COCO test-dev</strong>集上与<strong>SOTA</strong>方案的比较实验中，采用了<strong>Bigdet</strong>。<strong>SOTA</strong>结果是在<strong>576x432</strong>输入，采用<strong>1B</strong>参数量的<strong>ViTAE-G</strong>作为<strong>backbone</strong>，使用<strong>MS COCO + AI Challenger</strong>训练的情况下获得的。</p>

<p><img src="https://pic.imgdb.cn/item/64a391b71ddac507cc6cd092.jpg" alt="" /></p>

<h1 id="2-vitpose的特性">2. ViTPose的特性</h1>

<h3 id="-预训练的灵活性">⚪ 预训练的灵活性</h3>

<p>一般情况下<strong>backbone</strong>都需要<strong>ImageNet</strong>上预训练。本文提出了三种预训练方案：</p>
<ol>
  <li>采用<strong>ImageNet</strong>预训练分类任务，比较经典的方法，数据集总共<strong>1M</strong>图片</li>
  <li>采用<strong>MS COCO</strong>预训练<strong>MAE</strong>任务，将$75\%$的<strong>patch</strong>随机<strong>mask</strong>掉，然后让网络学习恢复这些<strong>patch</strong>，数据集共<strong>150K</strong>图片</li>
  <li>任务框架同方案<strong>2</strong>，不过数据集采用<strong>MS COCO + AI Challenger</strong>，共<strong>500K</strong>图片</li>
</ol>

<p>由于<strong>ViTPose</strong>是单人检测模型，因此将<strong>MS COCO</strong>和<strong>AI Challenger</strong>中的单个人体<strong>crop</strong>出来，与<strong>ImageNet</strong>单个<strong>object</strong>的数据分布保持一致。然后在<strong>3</strong>个数据集上分别训练<strong>1600</strong>个<strong>epoch</strong>，再在<strong>MS COCO</strong>上<strong>fine tune</strong> <strong>210</strong>个<strong>epoch</strong>。</p>

<p>采用<strong>VitPose-B</strong>结构，在<strong>MS COCO val set</strong>上，三种预训练方案的结果如下。可以看到使用<strong>MS COCO + AI Challenger</strong>，在只有一半数据量的情况下，可以达到比<strong>ImageNet</strong>更好的效果。</p>

<p><img src="https://pic.imgdb.cn/item/64a38f941ddac507cc6949b4.jpg" alt="" /></p>

<h3 id="-分辨率的灵活性">⚪ 分辨率的灵活性</h3>

<p><strong>ViTPose</strong>可以通过使用更大的输出尺寸来训练，也可以通过减小<strong>backbone</strong>中的下采样来构造更大尺度的<strong>feature map</strong>，这两种操作都能提高精度，具体如下：</p>
<ul>
  <li>更大尺寸的输入：直接缩放原始图像，得到对应大小的输入</li>
  <li>更大尺寸的特征：降低采样倍数，修改<strong>patch</strong>层的<strong>stride</strong>参数</li>
</ul>

<p>分辨率越大结果越高。</p>

<p><img src="https://pic.imgdb.cn/item/64a38fee1ddac507cc69df61.jpg" alt="" /></p>

<h3 id="-注意力的灵活性">⚪ 注意力的灵活性</h3>

<p><strong>Transformer</strong>中的<strong>Attention</strong>的计算量是<strong>Feature map</strong>尺寸的平方，因此是很大的，而且显存占用也很大。因此作者用了<strong>Shift Window</strong>和<strong>Pooling Window</strong>两种方案来缓解这个问题。</p>

<p><img src="https://pic.imgdb.cn/item/64a3904b1ddac507cc6a82d7.jpg" alt="" /></p>

<h3 id="-微调的灵活性">⚪ 微调的灵活性</h3>

<p>与<strong>NLP</strong>任务中一样，作者验证了只固定<strong>MHSA</strong>模块的参数，精度下降不多，而固定<strong>FFN</strong>的参数，则精度下降明显，因此作者认为<strong>MHSA</strong>更偏向与任务无关，而<strong>FFN</strong>则更具体任务关系更密切。</p>

<p><img src="https://pic.imgdb.cn/item/64a390881ddac507cc6adbd4.jpg" alt="" /></p>

<h3 id="-多任务的灵活性">⚪ 多任务的灵活性</h3>

<p>作者还尝试了采用同一个<strong>backbone</strong>，多个<strong>decoder</strong>，每个<strong>decoder</strong>对应一个数据集的任务，实验验证一次训练，多个数据集上的结果都能比较好，且比单个数据集精度有提升:</p>

<p><img src="https://pic.imgdb.cn/item/64a390c31ddac507cc6b37aa.jpg" alt="" /></p>

<h3 id="-蒸馏">⚪ 蒸馏</h3>

<p>作者提出了一个基于<strong>Transformer</strong>的蒸馏方法，与常见的用损失来监督<strong>Teacher</strong>和<strong>Student</strong>网络的思路不太一样，具体如下:</p>
<ol>
  <li>在大模型的<strong>patch embedding</strong>后的<strong>visual token</strong>后面增加一个知识<strong>token</strong>模块，并进行随机初始化</li>
  <li>固定大模型的参数，只训练知识<strong>token</strong>模块</li>
  <li>将训练好的知识<strong>token</strong>模块接到小模型的<strong>visual token</strong>后面，且固定知识<strong>token</strong>的参数，只训练小模型的其他参数</li>
</ol>

<p>通过这样的流程，将所有的知识都融合到了知识<strong>token</strong>模块的参数里面，并且从大模型传递到小模型。</p>

<p><img src="https://pic.imgdb.cn/item/64a391291ddac507cc6be18c.jpg" alt="" /></p>


    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2022/07/09/yolov5.html" class="read-next-link"></a>
        <section>
          <span>Comprehensive Guide to Ultralytics YOLOv5</span>
          <p>  YOLOv5：YOLO目标检测模型的第五次迭代.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/65274908c458853aefb02b56.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2022/07/07/poly.html" class="read-next-link"></a>
          <section>
            <span>PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions</span>
            <p>  PolyLoss：一种分类损失函数的多项式展开视角.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/6491587c1ddac507ccebb3ab.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
