<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>射频人体感知(RF-based Human Perception) - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="射频人体感知(RF-based Human Perception)">
    <meta name="keywords"  content="深度学习">
    <!-- Open Graph -->
    <meta property="og:title" content="射频人体感知(RF-based Human Perception) - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2024/06/01/rfbased.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="post-tag">深度学习</a>
          
        
      </div>
      <h1>射频人体感知(RF-based Human Perception)</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="24-06-01"><i class="iconfont icon-date"></i>01 Jun 2024</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/6749a84dd0e0a243d4db403d.png') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>Radio Frequency-based Human Perception.</p>
</blockquote>

<p>基于光学系统的人体感知是目前应用最广泛的人体感知技术，但它只在视距条件下有效，并且在低能见度、恶劣天气等环境中无法适用，且需要处理的数据量很大，另外在隐私保护性上也存在漏洞。在这些特殊场景中，非接触式的无侵害性的具备人体感知功能的传感器系统更符合人们的实际需求。</p>

<p><strong>射频</strong>信号 (<strong>Radio Frequency, RF</strong>) 是一种电磁波，其频率范围从<strong>30 kHz</strong>到<strong>3000 GHz</strong>。与光学频率范围的电磁波（如可见光）不同，射频信号具有独特的性质，使其成为特殊场景下的人体感知的有效工具。随着软硬件技术的发展和信号处理技术的成熟，射频系统（即雷达）的研制成本已降低，且雷达本身具有不受光照环境、非视距等因素制约的全时段、全天候的工作特点，因此可以弥补光学系统在人体感知应用中的不足。</p>

<p><img src="https://pic.imgdb.cn/item/6749a84dd0e0a243d4db403d.png" alt="" /></p>

<p><strong>射频人体感知(RF-based Human Perception)</strong>又称为<strong>可见光谱外的人体感知(perception beyond the visible spectrum)</strong>，是指使用雷达系统进行人体感知应用。雷达系统向检测环境中发射电磁波信号，照射人体目标，并接收反射信号用于执行下游任务。与光学系统相比，雷达系统可以在低能见度等特殊环境中工作，并且可以提供更好的隐私保护性。在特定频段工作的雷达系统还可以穿透墙壁等非金属障碍物，从而实现隐蔽场景下的人体感知。</p>

<p>根据发射信号的工作频段不同，射频人体感知方法可以细分为基于毫米波雷达的方法、基于<strong>WiFi</strong>阵列的方法与基于穿墙雷达的方法。</p>
<ul>
  <li>基于毫米波雷达的方法：工作频段30-300GHZ，人体目标被视为散射体，可以捕获细粒度的人体细节，如</li>
  <li>基于<strong>WiFi</strong>阵列的方法：工作频段2.4-5GHZ，人体目标被视为反射体，可以通过深度学习技术学习人体统计信息，如</li>
  <li>基于穿墙雷达的方法：工作频段0-3GHZ，超宽带穿墙雷达系统可用于非接触式穿墙人体感知，如。</li>
</ul>

<h1 id="1-基于毫米波雷达的方法">1. 基于毫米波雷达的方法</h1>
<p>毫米波（<strong>millimeter Wave，mmWave</strong>）雷达通常工作在相对较高的频率段（<strong>30-300 GHz</strong>），具有毫米尺度的空间分辨率。这些系统发射的信号波长相当于人体表面的粗糙度，因此人体目标被视为散射体，可以进一步感知反射目标的轻微不规则性，实现高精度的人体表面精细成像或同时获取目标的速度和距离信息，从而在捕获人体细节方面添加更多细粒度信息。</p>

<p>虽然这些基于毫米波雷达的方法可以准确地对人体表面成像，但它们对障碍物的穿透性很弱，因此无法检测被墙壁等障碍物遮挡的人体目标。此外这些系统的检测范围和目标数量有限（通常仅为单目标设计），系统成本较高且体积庞大。</p>

<h3 id="-mm-pose">⚪ <a href="https://0809zheng.github.io/2021/02/27/mmpose.html"><font color="blue">mm-Pose</font></a></h3>
<ul>
  <li>(arXiv1911) mm-Pose: Real-Time Human Skeletal Posture Estimation using mmWave Radars and CNNs</li>
</ul>

<p><strong>mm-Pose</strong>是一套利用<strong>77GHz</strong>毫米波雷达实时检测和跟踪人体姿态骨骼的系统。作者并有直接使用三维数据立方体，而是构造了新的信号表示：将雷达反射点投影到深度-方位平面和深度-高度平面，并将两个坐标值和归一化的反射功率作为通道信息。具有两个分支的卷积神经网络分别接收之前提到的两个方向的投影数据。网络输出为人体的25个关节点的空间坐标。</p>

<p><img src="https://img.imgdb.cn/item/6039f1525f4313ce25f40f2b.jpg" alt="" /></p>

<h3 id="-radarsrnn">⚪ <a href="https://0809zheng.github.io/2021/06/04/srcnn.html"><font color="blue">radarSRNN</font></a></h3>
<ul>
  <li>(Digital Signal Processing, 2019) Human motion recognition exploiting radar with stacked recurrent neural network</li>
</ul>

<p>作者提出了一种使用雷达采集的人类运动时间序列进行人体运动识别的方法。该方法采用<strong>LSTM</strong>构成的<strong>stacked RNN</strong>提取序列特征，并进行自动运动分类。利用原始雷达数据的光谱图作为网络输入，利用时变多普勒信号和微多普勒信号进行人体运动识别。</p>

<p>网络由两层<strong>LSTM</strong>层叠加组成，网络的输入是雷达光谱图，使用具有多个<strong>LSTM</strong>层的堆叠<strong>RNN</strong>结构提取动态运动信号，输出层输出了每个运动类别的概率。</p>

<p><img src="https://pic.imgdb.cn/item/60bad03f8355f7f718d1a5b3.jpg" alt="" /></p>

<h3 id="-itl">⚪ <a href="https://0809zheng.github.io/2021/06/11/mnet.html"><font color="blue">ITL</font></a></h3>
<ul>
  <li>(IEEE TGRS, 2020) Human Motion Recognition With Limited Radar Micro-Doppler Signatures</li>
</ul>

<p>本文提出了一种基于实例的迁移学习(<strong>ITL</strong>)方法，使用有限的雷达微多普勒信号进行人体运动识别，减轻了收集和标注大量雷达信号的负担。</p>

<p><strong>ITL</strong>的流程如图所示。首先设计了一个基于卷积神经网络的模型<strong>MNet</strong>，并在源数据集上进行预训练。其次设计相关源数据选择(<strong>CSDS</strong>)算法，从源域中提取部分实例，作为目标域数据的补充。最后设计自适应协同微调(<strong>ACFT</strong>)算法使用目标数据集和补充的源数据对<strong>MNet</strong>进行微调。</p>

<p><img src="https://pic.imgdb.cn/item/60c36079844ef46bb25060dd.jpg" alt="" /></p>

<h3 id="-1-d-dan">⚪ <a href="https://0809zheng.github.io/2021/05/13/1ddan.html"><font color="blue">1-D-DAN</font></a></h3>
<ul>
  <li>(IEEE GRSL 2021) Radar-Based Human Activity Recognition With 1-D Dense Attention Network</li>
</ul>

<p><strong>1-D-DAN</strong>用于基于微多普勒雷达的人类活动识别。该网络使用了专门为雷达光谱图设计的一维注意力机制，包括时间注意力分支和频率注意力分支；在该机制中还引入了可以充分利用网络特征的密集注意力操作。</p>

<p><img src="https://pic.imgdb.cn/item/609d0506d1a9ae528fe3120f.jpg" alt="" /></p>

<h1 id="2-基于wifi阵列的方法">2. 基于WiFi阵列的方法</h1>

<p><strong>WiFi</strong>阵列工作在较低频率段，由于电磁波信号的物理特性，这些设备通常具有较低的成像空间分辨率，因此单个雷达回波中携带的人体信息可能是不完整的。最近的方法试图通过深度学习技术从WiFi阵列获取的数据中学习人体的统计信息。</p>

<p>由于<strong>WiFi</strong>阵列的工作频段为<strong>2.4-5 GHz</strong>，带宽通常为<strong>20 MHz</strong>，较差的距离向分辨率与障碍物穿透性限制了人体感知的精度；且不可能直接从<strong>WiFi</strong>信号中截取人体的二维或三维像素，因此无法识别高精度以及远距离的人体目标。</p>

<h3 id="-rf-pose">⚪ <a href="https://0809zheng.github.io/2020/11/05/rfpose.html"><font color="blue">RF-Pose</font></a></h3>
<ul>
  <li>(CVPR 2018) Through-Wall Human Pose Estimation Using Radio Signals</li>
</ul>

<p>本文提出了一种使用<strong>WiFi</strong>信号穿过墙壁遮挡进行人体姿态估计的方法RF-Pose。使用具有两个天线阵列的<strong>WiFi</strong>系统，产生水平热图（反射信号在平行于地面的平面上的投影）和垂直热图（反射信号在垂直于地面的平面上的投影）。</p>

<p>由于人类无法直接标注<strong>WiFi</strong>热图，作者使用<strong>OpenPose</strong>视觉模型进行跨模态监督：在训练时系统同步使用<strong>WiFi</strong>热图和<strong>RGB</strong>图像作为输入，使用光学监督从射频数据中抽取姿态信息；测试时网络只使用射频数据进行姿态估计。</p>

<p><img src="https://pic.downk.cc/item/5fa3ad141cd1bbb86b57b896.jpg" alt="" /></p>

<h3 id="-rf-pose3d">⚪ <a href="https://0809zheng.github.io/2021/02/12/rfpose3d.html"><font color="blue">RF-Pose3D</font></a></h3>
<ul>
  <li>(SIGCOMM 2018) RF-Based 3D Skeletons</li>
</ul>

<p><strong>RF-Pose3D</strong>是一套使用射频信号构建具有$14$个关节点的<strong>3D</strong>人体骨骼重构系统，使用多天<strong>线FMCW</strong>结构，包括一个发射天线和两个垂直的接收天线，该系统主要由三部分构成：</p>
<ul>
  <li>卷积神经网络<strong>CNN</strong>：该模块接收人体反射的射频信号，并使用卷积网络推断人体的<strong>3D</strong>骨骼。由于射频信号具有空间和时间的$4$维信息，将<strong>4D</strong>卷积分解为两个平面和一个时间轴上的<strong>3D</strong>卷积的组合。</li>
  <li>区域提议网络<strong>RPN</strong>：为估计场景中所有人的骨骼，需要一个模块将每个个体的信号分离；使用一个深度神经网络放大来自特定个体的射频信号并将其与来自其他个体的信号分离。</li>
  <li>多相机子系统：网络训练需要标记数据；使用了由<strong>12</strong>个相机组成的系统，获取人体三维骨骼的位置。具体地，每个相机使用<strong>OpenPose</strong>从图像中提取二维骨骼，通过计算创建三维骨骼。</li>
</ul>

<p><img src="https://img.imgdb.cn/item/6025ff093ffa7d37b38c5c22.jpg" alt="" /></p>

<h3 id="-rf-avatar">⚪ <a href="https://0809zheng.github.io/2020/11/20/rfavatar.html"><font color="blue">RF-Avatar</font></a></h3>
<ul>
  <li>(ICCV 2019) Through-Wall Human Mesh Recovery Using Radio Signals</li>
</ul>

<p><strong>RF-Avatar</strong>是一种使用射频信号进行人体网格估计的方法。作者首先开发了一套在三维空间中检测和跟踪多人的射频系统，为每个个体生成运动轨迹；然后从检测到的轨迹中生成身体网格。</p>

<p>模型框架参考了<strong>Mask-RCNN</strong>模型，由两部分组成。轨迹提议网络(<strong>TPN</strong>)从输入的四维射频信号（三维空间+时间）中提取人体的运动轨迹；轨迹卷积神经网络(<strong>TCNN</strong>)从提取的轨迹特征中预测<strong>SMPL</strong>人体模型的参数。<strong>SMPL</strong>参数可以分解为与时间无关的形状向量和与时间相关的关节角。</p>

<p>此外作者设计了一种数据驱动的姿态和动力学判别器(<strong>PDD</strong>)，将预测的三维关节角度序列作为输入，旨在将其与真实的人体姿态和动力学数据区分开。</p>

<p><img src="https://pic.downk.cc/item/5fbb645cb18d627113e475fb.jpg" alt="" /></p>

<h3 id="-twpirt-mmedp">⚪ <a href="https://0809zheng.github.io/2021/02/03/twpose.html"><font color="blue">TWPIRT-MMEDP</font></a></h3>
<ul>
  <li>(arXiv1904) Through-Wall Pose Imaging in Real-Time with a Many-to-Many Encoder/Decoder Paradigm</li>
</ul>

<p>作者提出了使用射频信号在视觉遮挡的视频中重建具有<strong>15</strong>个关键点的人体姿态。模型采用学生-教师网络，使用光学相机和<strong>RF</strong>阵列天线同时收集视频帧和<strong>RF</strong>数据，教师网络从视频帧中生成每帧的人体姿态骨骼，学生网络从<strong>RF</strong>数据中预测相同类型的骨骼（使用<strong>CNN</strong>从<strong>RF</strong>数据中提取空间特征，使用<strong>RPN</strong>从特征中检测场景中所有人，使用<strong>LSTM</strong>在多个时间步长上聚集信息）。</p>

<p><img src="https://img.imgdb.cn/item/601a51eb3ffa7d37b3dcb089.jpg" alt="" /></p>

<h3 id="-person-in-wifi">⚪ <a href="https://0809zheng.github.io/2021/03/04/personinwifi.html"><font color="blue">Person-in-WiFi</font></a></h3>
<ul>
  <li>(arXiv1904) Person-in-WiFi: Fine-grained Person Perception using WiFi</li>
</ul>

<p><strong>Person-in-WiFi</strong>是一种使用<strong>1D</strong>传感器（即现成的<strong>WiFi</strong>天线）实现人体感知任务的方法。作者分别使用包含3个天线的标准<strong>WiFi</strong>路由器作为发射天线和接收天线，以<strong>2.4GHz</strong>为中心划分了<strong>30</strong>个电磁频率，即信号在接收天线上会产生<strong>30</strong>种不同的接收模式以感知不同尺度的物体。</p>

<p>作者使用一台固定到接收天线的<strong>RGB</strong>相机收集视频信号，并人工制作标签。对于人体图像分割的标签，使用<strong>Mask R-CNN</strong>生成分割热图<strong>SM</strong>。对于姿态估计的标签，使用<strong>Openpose</strong>生成关节点热图<strong>JHMs</strong>和部位亲和场<strong>PAFs</strong>。</p>

<p>网络的输入张量尺包含5个样本。将其通过上采样调整尺寸，再通过残差卷积、<strong>U-Net</strong>得到更丰富的特征图，再根据任务需求进行下采样，生成用于图像分割的<strong>SM</strong>和用于姿态估计的<strong>JHMs</strong>和<strong>PAFs</strong>。</p>

<p><img src="https://img.imgdb.cn/item/60408d2e360785be5447c236.jpg" alt="" /></p>

<h3 id="-rf-action">⚪ <a href="https://0809zheng.github.io/2022/06/29/rfaction.html"><font color="blue">RF-Action</font></a></h3>
<ul>
  <li>(arXiv1909) Making the Invisible Visible: Action Recognition Through Walls and Occlusions</li>
</ul>

<p><strong>RF-Action是</strong>一个端到端的神经网络模型，可以在遮挡和恶劣照明条件下检测人类目标的行为。模型将射频信号作为输入，生成三维人体骨架作为中间表示，并识别多人随时间的动作和交互。</p>

<p>动作检测模型有三个模块：</p>
<ul>
  <li>基于注意力的特征学习网络: 从每个骨架序列中提取高层次的时空特征。</li>
  <li>多提案模块：提取提案，每个提案对应于行动开始和结束的时间窗口。多提案模块由两个提案子网络组成：一个用于生成单人行动的提案，另一个用于两人互动。</li>
  <li>根据生成的提案来裁剪和调整相应的隐特征，并将每个裁剪的动作片段输入到分类网络中。分类网络首先通过执行双向分类来细化时间提案，以确定该持续时间内是否包含动作。然后预测相应的动作类别。</li>
</ul>

<p><img src="https://pic.imgdb.cn/item/6306d02116f2c2beb101953f.jpg" alt="" /></p>

<h3 id="-wipose">⚪ <a href="https://0809zheng.github.io/2021/03/05/3dwifi.html"><font color="blue">WiPose</font></a></h3>
<ul>
  <li>(MobiCom 2020) Towards 3D Human Pose Construction Using WiFi</li>
</ul>

<p><strong>WiPose</strong>是一套利用<strong>WiFi</strong>信号重构<strong>3D</strong>人体姿态的系统。该系统将人体骨骼的先验知识引入重构过程中，从<strong>WiFi</strong>信号中提取通道状态信息<strong>CSI</strong>作为输入，从而捕捉三维空间中的运动情况，并采用<strong>LSTM</strong>和平滑损失构造姿态骨骼。系统使用<strong>VICON</strong>光学系统收集数据并进行人工标注，从而为训练提供人体关节点坐标标签。</p>

<p><img src="https://img.imgdb.cn/item/604195a8360785be54b2ded6.jpg" alt="" /></p>

<h3 id="-rf-reid">⚪ <a href="https://0809zheng.github.io/2022/06/23/rfreid.html"><font color="blue">RF-ReID</font></a></h3>
<ul>
  <li>(arXiv2004) Learning Longterm Representations for Person Re-Identification Using Radio Signals</li>
</ul>

<p><strong>RF-ReID</strong>使用射频信号进行<strong>ReID</strong>任务。<strong>Wi-Fi</strong>频率范围内的射频信号能够穿过衣服并反射人体，从而提取人体的固有特征，如身体大小或形状，而这些特征在长期时间段内相对稳定。</p>

<p><strong>RF-ReID</strong>模型使用射频<strong>tracklet</strong>作为输入。<strong>tracklet</strong>使用边界框描述了水平和垂直热图中人体反射的射频轨迹，每个射频<strong>tracklet</strong>对应一个人体目标。该模型使用一个特征提取网络从<strong>tracklet</strong>中提取特征，然后通过一个可学习的层次注意力模块聚合时间信息以生成特征图。</p>

<p>此外作者提出了一个多任务学习框架和一个环境判别器。除了预测目标的身份外，该框架通过强制模型学习的特征包含足够的信息来预测人体的三维姿态骨骼。环境判别器通过对抗学习强制特征与当前环境无关，与特征提取网络共同训练。</p>

<p><img src="https://pic.imgdb.cn/item/62b5950b0947543129bca8f0.jpg" alt="" /></p>

<h3 id="-tgul">⚪ <a href="https://0809zheng.github.io/2022/05/06/unsupervisedrf.html"><font color="blue">TGUL</font></a></h3>
<ul>
  <li>(WACV 2022) Unsupervised Learning for Human Sensing Using Radio Signals</li>
</ul>

<p><strong>TGUL</strong>是一种轨迹引导的无监督学习方法，该方法通过基于雷达的模块探测目标并跟踪他们的轨迹，在任何时刻放大包含目标的检测区域，并消除其他物体的反射信号，在该区域内应用无监督训练损失。作者探讨了两种适用于射频信号的自监督任务：</p>
<ol>
  <li>通过预测无监督学习从射频信号中学习人体特征表示；<img src="https://pic.imgdb.cn/item/6274deb8094754312967b9ca.jpg" alt="" /></li>
  <li>通过对比无监督学习从射频信号中学习人体特征表示。<img src="https://pic.imgdb.cn/item/6274e43d094754312975768b.jpg" alt="" /></li>
</ol>

<h1 id="3-基于穿墙雷达的方法">3. 基于穿墙雷达的方法</h1>

<p>穿墙雷达（<strong>Through-Wall Radar，TWR</strong>）系统发射宽频带低功率脉冲信号，不仅具有较大距离向分辨率和较强抗干扰能力，还能够在较宽的检测区域中捕捉丰富的三维人体信息，扩展了人体感知的应用场景。</p>

<p>其中具有厘米量级距离向分辨率的超宽带穿墙雷达系统以其测距精度高、穿透障碍物能力强、目标分辨能力高和反隐身能力好等优点，在非接触式穿墙人体感知领域体现出巨大潜力。</p>

<h3 id="-uda-mdhmc">⚪ <a href="https://0809zheng.github.io/2021/05/17/uda.html"><font color="blue">UDA-MDHMC</font></a></h3>
<ul>
  <li>(IEEE GRSL 2018) Unsupervised Domain Adaptation for Micro-Doppler Human Motion Classification via Feature Fusion</li>
</ul>

<p>本文提出了一种用于微多普勒分类的无监督域适应方法。使用运动捕捉数据库<strong>MOCAP</strong>作为源数据集，为了提取域不变的特征，融合了三种特征，包括卷积神经网络中的浅层特征、经验特征和统计特征。将这些特征融合后，使用k最近邻分类器，对七种人类活动进行分类。</p>

<p><img src="https://pic.imgdb.cn/item/60a22e526ae4f77d358a4776.jpg" alt="" /></p>

<h3 id="-ada-mdhac">⚪ <a href="https://0809zheng.github.io/2021/05/18/uada.html"><font color="blue">ADA-MDHAC</font></a></h3>
<ul>
  <li>(IEEE GRSL 2019) Unsupervised Adversarial Domain Adaptation for Micro-Doppler Based Human Activity Classification</li>
</ul>

<p>本文提出了一种使用微多普勒信号进行人类活动分类的域适应方法，主要关注从仿真到真实世界的域适应。首先使用运动捕捉(<strong>MOCAP</strong>)数据库生成模拟的微多普勒数据，用于训练卷积神经网络。然后引入一个域判别器处理卷积网络的特征提取部分，用于区别仿真数据和真实数据。通过对抗训练，将在仿真数据中训练的卷积网络推广到真实数据中，并在微多普勒分类中的准确率超过现有的方法。</p>

<p><img src="https://pic.imgdb.cn/item/60a22fa96ae4f77d3594e796.jpg" alt="" /></p>

<h3 id="-scgrnn">⚪ <a href="https://0809zheng.github.io/2021/06/12/scgrnn.html"><font color="blue">SCGRNN</font></a></h3>
<ul>
  <li>(Neurocomputing, 2020) Segmented convolutional gated recurrent neural networks for human activity recognition in ultra-wideband radar</li>
</ul>

<p>分段卷积门控循环神经网络(<strong>SCGRNN</strong>)使用超宽带雷达的微多普勒光谱图进行人体活动识别。该模型首先通过卷积操作提取光谱图的分段特征，再用<strong>GRU</strong>沿时间轴对特征图进行编码，从而实现检测任意长度光谱图中的人体活动。</p>

<p><img src="https://pic.imgdb.cn/item/60c426ca844ef46bb25042d1.jpg" alt="" /></p>

<h3 id="-twhpr-uwb">⚪ <a href="https://0809zheng.github.io/2021/02/25/uwbmimo.html"><font color="blue">TWHPR-UWB</font></a></h3>
<ul>
  <li>(Remote Sensing 2021) Through-Wall Human Pose Reconstruction via UWB MIMO Radar and 3D CNN</li>
</ul>

<p>作者为超宽带(<strong>UWB</strong>) <strong>MIMO</strong>雷达设计了一套<strong>3D</strong>人体姿态重构方法。首先使用<strong>UWB MIMO</strong>雷达捕获人体信息。 然后使用目标检测方法锁定目标位置，采用反向投影(<strong>BP</strong>)算法构造三维图像。 最后将处理后的三维图像为输入，通过三维<strong>CNN</strong>模型重建人体目标的三维姿态。</p>

<p><img src="https://img.imgdb.cn/item/603749ea5f4313ce25eec05f.jpg" alt="" /></p>

<h3 id="-uwb-pose">⚪ <a href="https://0809zheng.github.io/2022/02/26/efficientradar.html"><font color="blue">UWB-Pose</font></a></h3>
<ul>
  <li>(IEEE AWPL 2021) Efficient Through-wall Human Pose Reconstruction Using UWB MIMO Radar</li>
</ul>

<p>本文提出了一种基于超宽带多输入多输出雷达的穿墙人体姿态重构网络<strong>UWB-Pose</strong>，首先使用雷达系统构建人体的<strong>3D</strong>雷达图像，并将雷达图像转换为离散的<strong>3D</strong>点，通过设计一个轻量级的网络，从输入点数据中提取人体特征，并将特征转换为三维姿态坐标。</p>

<p><img src="https://pic.imgdb.cn/item/6219921b2ab3f51d91567088.jpg" alt="" /></p>

<h3 id="-uwb-pose-1">⚪ <a href="https://0809zheng.github.io/2021/05/16/tlel.html"><font color="blue">UWB-Pose</font></a></h3>
<ul>
  <li>(IEEE GRSL 2021) Through-Wall Human Motion Recognition Based on Transfer Learning and Ensemble Learning</li>
</ul>

<p>本文提出了一个基于迁移学习和集成学习的多雷达协同人体运动识别模型。将预训练的<strong>ResNeXt</strong>网络迁移到基于多雷达的运动识别任务中，解决了训练样本较少的问题；在不提高模型复杂度的情况下提高识别精度，并降低了超参数的数量。在单一视角下的模型准确率较低，采用多雷达协同工作的方法，通过集成学习进一步提高识别精度。</p>

<p><img src="https://pic.imgdb.cn/item/60bb490b8355f7f718f13d05.jpg" alt="" /></p>

<h3 id="-扩展阅读">⚪ 扩展阅读：</h3>
<ul>
  <li><a href="https://0809zheng.github.io/2021/02/06/throughwall.html">A Survey of Handy See-Through Wall Technology</a>：(IEEE2020)一篇关于穿墙系统原理与应用的综述。</li>
  <li><a href="https://0809zheng.github.io/2021/01/29/radar.html">3D Imaging of Moving Targets for Ultra-wideband MIMO Through-wall Radar System</a>：(IET RSN2020)使用UWB MIMO雷达进行三维运动目标成像。</li>
</ul>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2024/06/02/radarformer.html" class="read-next-link"></a>
        <section>
          <span>RadarFormer: End-to-End Human Perception With Through-Wall Radar and Transformers</span>
          <p>  RadarFormer：基于Transformer的穿墙雷达端到端人体感知.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/674da14ad0e0a243d4dc1825.png" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2024/05/23/yolov10.html" class="read-next-link"></a>
          <section>
            <span>YOLOv10: Real-Time End-to-End Object Detection</span>
            <p>  YOLOv10：实时端到端目标检测.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/668bb30cd9c307b7e9d3b5ac.png" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
