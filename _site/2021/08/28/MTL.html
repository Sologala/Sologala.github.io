<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>多任务学习(Multi-Task Learning) - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="多任务学习(Multi-Task Learning)">
    <meta name="keywords"  content="深度学习">
    <!-- Open Graph -->
    <meta property="og:title" content="多任务学习(Multi-Task Learning) - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2021/08/28/MTL.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="post-tag">深度学习</a>
          
        
      </div>
      <h1>多任务学习(Multi-Task Learning)</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="21-08-28"><i class="iconfont icon-date"></i>28 Aug 2021</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.imgdb.cn/item/612ca4ee44eaada739024c7c.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>Multi Task Learning.</p>
</blockquote>

<p>本文目录：</p>
<ol>
  <li>多任务学习的定义及特点</li>
  <li>多任务学习的网络结构</li>
  <li>多任务学习的损失函数</li>
</ol>

<h1 id="1-多任务学习的定义及特点">1. 多任务学习的定义及特点</h1>
<p><strong>多任务学习</strong>(<strong>multi-task learning, MTL</strong>)是指同时学习多个属于不同领域(<strong>domain</strong>)的任务，并通过特定任务的领域信息提高泛化能力。</p>

<p><strong>MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks</strong>.</p>

<p>多任务学习的<strong>特点</strong>如下：</p>
<ul>
  <li>同时学习多个任务，若某个任务中包含对另一个任务有用的信息，则能够提高在后者上的表现；</li>
  <li>具有正则化的效果，即模型不仅需要在一个任务上表现较好，还需要再别的任务上表现好；相当于引入了归纳偏置(<strong>inductive bias</strong>)，即倾向于学习到在多个任务上表现都比较好的特征；</li>
  <li>模型可以共享部分结构，降低内存占用(<strong>memory footprint</strong>)，减少重复计算，提高推理速度。</li>
</ul>

<p>通常<strong>MTL</strong>处理的任务应具有一定的关联性。若同时学习两个不相关甚至有冲突的任务，可能会损害模型的表现，这个现象称为<strong>negative transfer</strong>。</p>

<p>与标准的单任务学习相比，多任务学习的方法设计可以分别从<strong>网络结构</strong>与<strong>损失函数</strong>两个角度出发。</p>

<h1 id="2-多任务学习的网络结构">2. 多任务学习的网络结构</h1>

<p>一个高效的多任务网络，应同时兼顾特征共享部分和任务特定部分，既需要学习任务之间的泛化表示(避免过拟合)，又需要学习每个任务独有的特征(避免欠拟合)。</p>

<p>根据模型在处理不同任务时网络参数的共享程度，<strong>MTL</strong>方法的网络结构可分为：</p>
<ul>
  <li><strong>硬参数共享 (Hard Parameter Sharing)</strong>：模型的主体部分共享参数，输出结构任务独立。</li>
  <li><strong>软参数共享 (Soft Parameter Sharing)</strong>：不同任务采用独立模型，模型参数彼此约束。</li>
</ul>

<p><img src="https://pic.imgdb.cn/item/62dbe42df54cd3f937f34a2a.jpg" alt="" /></p>

<h2 id="1-硬参数共享-hard-parameter-sharing">(1) 硬参数共享 Hard Parameter Sharing</h2>

<p><strong>Hard Parameter Sharing</strong>是指模型在处理不同任务时，其主体部分共享参数，针对不同任务使用不同的输出结构。这类方法通过在不同任务上学习共享的特征，降低模型在单个任务上过拟合的风险。</p>

<h3 id="-multilinear-relationship-network使用张量正态先验约束输出结构">⚪ <a href="https://0809zheng.github.io/2021/09/26/mrn.html"><font color="Blue">Multilinear Relationship Network</font></a>：使用张量正态先验约束输出结构</h3>

<p><img src="https://pic.imgdb.cn/item/62dfadfcf54cd3f937aef46b.jpg" alt="" /></p>

<h3 id="-fully-adaptive-feature-sharing通过全自适应特征共享逐层加宽网络">⚪ <a href="https://0809zheng.github.io/2021/09/27/fafs.html"><font color="Blue">Fully-adaptive Feature Sharing</font></a>：通过全自适应特征共享逐层加宽网络</h3>

<p><img src="https://pic.imgdb.cn/item/62e0fbe4f54cd3f937c0e54b.jpg" alt="" /></p>

<h2 id="2-软参数共享-soft-parameter-sharing">(2) 软参数共享 Soft Parameter Sharing</h2>

<p><strong>Soft Parameter Sharing</strong>是指针对每个任务使用具有独立参数的模型，对不同任务的模型参数进行额外的距离约束。这类方法通常能够在单个任务上实现更好的表现，但模型参数与任务数量呈倍数增长。</p>

<h3 id="-cross-stitch-network使用线性组合构造特征图">⚪ <a href="https://0809zheng.github.io/2021/09/28/csn.html"><font color="Blue">Cross-Stitch Network</font></a>：使用线性组合构造特征图</h3>

<p><img src="https://pic.imgdb.cn/item/62de4275f54cd3f937854565.jpg" alt="" /></p>

<h3 id="-sluice-network使用线性组合构造层次化特征图">⚪ <a href="https://0809zheng.github.io/2021/09/29/sluice.html"><font color="Blue">Sluice Network</font></a>：使用线性组合构造层次化特征图</h3>

<p><img src="https://pic.imgdb.cn/item/62de4c82f54cd3f937b9f90f.jpg" alt="" /></p>

<h3 id="-multi-task-attention-network使用注意力机制设置构造特征图">⚪ <a href="https://0809zheng.github.io/2021/09/06/dwa.html"><font color="Blue">Multi-Task Attention Network</font></a>：使用注意力机制设置构造特征图</h3>

<p><img src="https://pic.imgdb.cn/item/6132d2ef44eaada739241dd0.jpg" alt="" /></p>

<h1 id="3-多任务学习的损失函数">3. 多任务学习的损失函数</h1>

<p>多任务学习将多个相关的任务共同训练，其总损失函数是每个任务的损失函数的加权求和式：\(\mathcal{L}_{total} = \sum_{k}^{} w_k\mathcal{L}_k\)。权重的选择应能够平衡每个任务的训练，使得各任务都获得有益的提升。</p>

<h2 id="1-如何设置权重帕累托最优">(1) 如何设置权重：帕累托最优</h2>

<p>多任务学习的目的是寻找模型的最优参数$\theta^{*}$。若该参数任意变化都会导致某个任务$k$的损失函数\(\mathcal{L}_k\)增大，则称$\theta^{*}$为<a href="https://0809zheng.github.io/2021/09/25/pareto.html">帕累托最优解(Pareto Optimality)</a>。帕累托最优意味着每个任务的损失都比较小，不能通过牺牲某个任务来换取另一个任务的性能提升。</p>

<p>若参数的更新过程采用梯度下降法，则多任务学习的主要工作是寻找一个尽可能与每个任务的梯度\(\nabla_{\theta} \mathcal{L}_k\)都相反的方向作为更新方向，等价于构造向量$u$使得参数更新方向为$\Delta \theta = -\eta u$。构造最优化问题：</p>

\[\forall k, \langle \nabla_{\theta} \mathcal{L}_k,u \rangle \geq 0  \Leftrightarrow  \mathop{\min}_{k} \langle \nabla_{\theta} \mathcal{L}_k,u \rangle \geq 0   \Leftrightarrow  \mathop{\max}_{u} \mathop{\min}_{k} \langle \nabla_{\theta} \mathcal{L}_k,u \rangle\]

<p>若定义\(\Bbb{P}^K\)为所有$K$元离散分布的集合：</p>

\[\Bbb{P}^K = \{ (w_1,w_2,\cdots,w_K) | w_1,w_2,\cdots,w_K\geq 0,\sum_{k} w_k = 1 \}\]

<p>则优化目标等价于：</p>

\[\mathop{\min}_{k} \langle \nabla_{\theta} \mathcal{L}_k,u \rangle  =  \mathop{\min}_{w \in \Bbb{P}^K} \langle \sum_k w_k\nabla_{\theta} \mathcal{L}_k,u \rangle  = \mathop{\min}_{w \in \Bbb{P}^K} \langle \sum_k \nabla_{\theta} w_k\mathcal{L}_k,u \rangle\]

<p>因此通过为损失函数\(\mathcal{L}_k\)设置合适的权重$w_k$，使得上述目标取得最小值，并进一步选择使得该最小值最大的向量$u$，便可以构造使目标逐渐接近帕累托最优的参数更新方向。</p>

<p>本节首先介绍一些权重的手动设置方法，并讨论它们的特点；下一节将介绍一些自动设置权重的方法。</p>

<h3 id="-根据初始状态设置权重">⚪ 根据初始状态设置权重</h3>
<p>在没有任何任务先验的情况下，总损失可以设置为所有任务损失的算术平均值，即$w_k=1/K$。然而每个任务的损失函数的数量级和物理量纲都不同，因此可以使用损失函数初始值的倒数进行<strong>无量纲化</strong>：</p>

\[w_k = \frac{1}{\mathcal{L}_k^{(0)}}\]

<p>该权重具有<strong>缩放不变性</strong>，即任务$k$的损失大小进行缩放后结果不会变化。</p>

<p>损失函数初始值既可以取前几次批量的损失平均估计，也可以基于任务假设得到理论值。比如假设模型的初始输出是零向量，则$C$分类任务的初始损失为$-\log \frac{1}{C}=\log C$；而回归任务的初始损失为$\Bbb{E}_y[||y-0||^2]=\Bbb{E}_y[||y||^2]$。</p>

<h3 id="-根据先验状态设置权重">⚪ 根据先验状态设置权重</h3>

<p>若能够预先获取数据集的标签信息，则可以根据其统计值构造损失函数的先验状态\(\mathcal{L}_k^{\text{prior}}\)，并用作权重：</p>

\[w_k = \frac{1}{\mathcal{L}_k^{\text{prior}}}\]

<p>先验状态可以代表当前任务的初始难度。比如$C$分类任务中统计每个类别的出现频率为$[p_1,\cdots,p_K]$，则先验状态\(\mathcal{L}_k^{\text{prior}}=-\sum_{k}^{K}p_k\log p_k\)；而回归任务的中统计所有样本标签的期望\(\mu = \Bbb{E}_y[y]\)，则先验状态\(\mathcal{L}_k^{\text{prior}}=\Bbb{E}_y[\|y-\mu\|^2]\)。</p>

<h3 id="-根据实时状态设置权重">⚪ 根据实时状态设置权重</h3>

<p>根据初始状态和先验状态设定的权重都是固定值，更合理的方案是根据训练过程中的实时状态动态地调整权重：</p>

\[w_k^{(t)} = \frac{1}{sg(\mathcal{L}_k^{(t)})}\]

<p>其中$sg(\cdot)$表示<strong>stop gradient</strong>，即在反向传播时不计算其梯度，在<strong>pytorch</strong>中可以通过<code class="language-plaintext highlighter-rouge">.detach()</code>方法实现。在该权重设置下，虽然每个任务的损失函数恒为$1$，但梯度不恒为$0$；对应的总损失函数梯度表示为：</p>

\[\begin{aligned} \nabla_{\theta} \mathcal{L}_{total} &amp;= \nabla_{\theta} \sum_k^K \frac{\mathcal{L}_k}{sg(\mathcal{L}_k^{(t)})}  = \sum_k^K \nabla_{\theta} \frac{\mathcal{L}_k}{sg(\mathcal{L}_k^{(t)})} = \sum_k^K \frac{\nabla_{\theta} \mathcal{L}_k}{\mathcal{L}_k^{(t)}} \\ &amp;= \sum_k^K \nabla_{\theta} \log \mathcal{L}_k = \nabla_{\theta} \log \prod_k^K  \mathcal{L}_k = \nabla_{\theta} K\log \sqrt[K]{\prod_k^K  \mathcal{L}_k} \end{aligned}\]

<p>此时总损失函数等价于每个任务的损失函数的<strong>几何平均值</strong>。</p>

<h3 id="-根据梯度状态设置权重">⚪ 根据梯度状态设置权重</h3>

<p>上述几种权重设置都具有<strong>缩放不变性</strong>；却不具有<strong>平移不变性</strong>，即任务$k$的损失加上一个常数后结果会发生变化。因此考虑采用损失函数梯度的模长来代替损失本身，以构造权重：</p>

\[w_k^{(t)} = \frac{1}{sg(||\nabla_{\theta} \mathcal{L}_k^{(t)}||)}\]

<p>该权重同时具有缩放与平移不变性。此时总损失函数的梯度表示为：</p>

\[\nabla_{\theta} \mathcal{L}_{total} = \nabla_{\theta} \sum_k^K \frac{\mathcal{L}_k}{sg(||\nabla_{\theta} \mathcal{L}_k^{(t)}||)}  = \sum_k^K \frac{\nabla_{\theta} \mathcal{L}_k}{sg(||\nabla_{\theta} \mathcal{L}_k^{(t)}||)}\]

<p>因此该权重设置等价于将每个任务损失的梯度进行<strong>归一化</strong>后，再把梯度累加起来参与梯度更新。</p>

<h2 id="2-权重的自动设置">(2) 权重的自动设置</h2>

<p>多任务学习的损失函数形式为\(\mathcal{L}_{total} = \sum_{k}^{} w_k\mathcal{L}_k\)，对每个任务的损失进行权重分配。如何自动进行权重选择，避免网络过于关注某任务是十分重要的。下面介绍一些权重自动选择方法：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">方法</th>
      <th style="text-align: center">权重</th>
      <th style="text-align: center">辅助参数</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/09/05/uncertainty.html"><font color="Blue">Uncertainty</font></a>：根据<strong>同方差不确定度</strong>设置权重</td>
      <td style="text-align: center">\(\sum_{k=1}^{K}\frac{1}{2\sigma_k^2}\mathcal{L}_k(\theta)+\log \sigma_k\)</td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/09/08/gradnorm.html"><font color="Blue">Gradient Normalization</font></a>：根据<strong>梯度量级</strong>和<strong>训练速度</strong>更新权重</td>
      <td style="text-align: center">\(w_k^{(t+1)}  \gets w_k^{(t)}-\lambda \nabla_{w_k}\mathcal{L}_{\text{grad}}\)</td>
      <td style="text-align: center">\(\begin{aligned}  \mathcal{L}_{\text{grad}}(t;w_k^{(t)}) &amp;= \sum_{k=1}^{K} | G_k^{(t)}-\overline{G}^{(t)} \times [r_k^{(t)}]^{\alpha} |_1 \\ G_k^{(t)} = || &amp; \nabla_{\theta}w_k^{(t)}\mathcal{L}_k||_2 ,\overline{G}^{(t)} = \Bbb{E}_k[ G_k^{(t)}] \\ r_k^{(t)} &amp;= \frac{\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}}{\Bbb{E}_k[\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}]} \end{aligned}\)</td>
    </tr>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/09/06/dwa.html"><font color="Blue">Dynamic Weight Average</font></a>：根据<strong>损失相对下降率</strong>设置权重</td>
      <td style="text-align: center">\(w_k^{(t)} = \frac{K \exp(r_k^{(t-1)}/T)}{\sum_{i}^{}\exp(r_i^{(t-1)}/T)}\)</td>
      <td style="text-align: center">\(r_k^{(t-1)}=\frac{\mathcal{L}_k^{(t-1)}}{\mathcal{L}_k^{(t-2)}}\)</td>
    </tr>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/09/25/pareto.html"><font color="Blue">Multi-Objective Optimization</font></a>：通过<strong>Frank-Wolfe</strong>算法求<strong>帕累托最优解</strong></td>
      <td style="text-align: center">\(w_k^{(t+1)} = (1-\gamma)w_k^{(t)}+\gamma e_{\tau}\)</td>
      <td style="text-align: center">\(\begin{aligned} \tau &amp;= \mathop{\arg \min}_k \langle \nabla_{\theta} \mathcal{L}_k,\sum_k w_k^{(t)}\mathcal{L}_k \rangle \\ \gamma &amp;=  \mathop{\arg \min}_{\gamma} \sum_k((1-\gamma)w_k^{(t)}+\gamma e_{\tau} )\mathcal{L}_k  \end{aligned}\)</td>
    </tr>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/10/09/dtp.html"><font color="Blue">Dynamic Task Prioritization</font></a>：根据<strong>动态任务优先级</strong>设置权重</td>
      <td style="text-align: center">\(w_k^{(t)} =  -(1-\overline{\kappa}_k^{(t)})^{\gamma_t} \log(\overline{\kappa}_k^{(t)})\)</td>
      <td style="text-align: center">\(\overline{\kappa}_k^{(t)} = \alpha * \kappa_k^{(t)} + (1-\alpha) * \overline{\kappa}_k^{(t-1)}\)</td>
    </tr>
    <tr>
      <td style="text-align: center"><a href="https://0809zheng.github.io/2021/09/07/lbtw.html"><font color="Blue">Loss-Balanced Task Weighting</font></a>：根据<strong>损失变化</strong>设置权重</td>
      <td style="text-align: center">\(w_k^{(t)} = (\frac{\mathcal{L}_k^{(t)}}{\mathcal{L}_k^{(0)}})^{\alpha}\)</td>
      <td style="text-align: center">-</td>
    </tr>
  </tbody>
</table>

<h1 id="-参考文献">⚪ 参考文献</h1>
<ul>
  <li><a href="https://arxiv.org/abs/1706.05098">An Overview of Multi-Task Learning in Deep Neural Networks</a>：(arXiv1706)一篇多任务学习综述。</li>
  <li><a href="https://arxiv.org/abs/1707.08114">A Survey on Multi-Task Learning</a>：(arXiv1707)一篇多任务学习综述。</li>
  <li><a href="https://arxiv.org/abs/2004.13379">Multi-Task Learning for Dense Prediction Tasks: A Survey</a>：(arXiv2004)一篇多任务学习综述。</li>
  <li><a href="https://arxiv.org/abs/2009.09796">Multi-Task Learning with Deep Neural Networks: A Survey</a>：(arXiv2009)一篇多任务学习综述。</li>
  <li><a href="https://0809zheng.github.io/2021/09/26/mrn.html"><font color="Blue">Learning Multiple Tasks with Multilinear Relationship Networks</font></a>：(arXiv1506)MRN：使用多线性关系网络进行多任务学习。</li>
  <li><a href="https://0809zheng.github.io/2021/09/28/csn.html"><font color="Blue">Cross-stitch Networks for Multi-task Learning</font></a>：(arXiv1604)Cross-stitch Network：用于多任务学习的十字绣网络。</li>
  <li><a href="https://0809zheng.github.io/2021/09/27/fafs.html"><font color="Blue">Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification</font></a>：(arXiv1611)多任务网络中的全自适应特征共享及其在目标属性分类中的应用。</li>
  <li><a href="https://0809zheng.github.io/2021/09/29/sluice.html"><font color="Blue">Sluice networks: Learning what to share between loosely related tasks</font></a>：(arXiv1705)水闸网络：学习松散相关任务之间的共享表示。</li>
  <li><a href="https://0809zheng.github.io/2021/09/05/uncertainty.html"><font color="Blue">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</font></a>：(arXiv1705)使用同方差不确定性调整多任务损失权重。</li>
  <li><a href="https://0809zheng.github.io/2021/09/08/gradnorm.html"><font color="Blue">GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</font></a>：(arXiv1711)GradNorm: 使用梯度标准化调整多任务损失权重。</li>
  <li><a href="https://0809zheng.github.io/2021/09/06/dwa.html"><font color="Blue">End-to-End Multi-Task Learning with Attention</font></a>：(arXiv1803)多任务注意力网络与动态权重平均。</li>
  <li><a href="https://0809zheng.github.io/2021/09/25/pareto.html"><font color="Blue">Multi-Task Learning as Multi-Objective Optimization</font></a>：(arXiv1810)把多任务学习建模为多目标优化问题。</li>
  <li><a href="https://0809zheng.github.io/2021/10/09/dtp.html"><font color="Blue">Dynamic Task Prioritization for Multitask Learning</font></a>：(ECCV2018)多任务学习中的动态任务优先级。</li>
  <li><a href="https://0809zheng.github.io/2021/09/07/lbtw.html"><font color="Blue">Loss-Balanced Task Weighting to Reduce Negative Transfer in Multi-Task Learning</font></a>：(AAAI2019)通过损失平衡任务加权解决多任务学习中的负迁移。</li>
</ul>


    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2021/08/29/lrelu.html" class="read-next-link"></a>
        <section>
          <span>Rectifier Nonlinearities Improve Neural Network Acoustic Models</span>
          <p>  LeakyReLU：使用修正的非线性提高神经网络声学模型.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/6128a89344eaada7392b17f3.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2021/08/27/deepersuper.html" class="read-next-link"></a>
          <section>
            <span>Training Deeper Convolutional Networks with Deep Supervision</span>
            <p>  使用深度监督训练更深的卷积网络.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/6126273144eaada73944f2cb.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
