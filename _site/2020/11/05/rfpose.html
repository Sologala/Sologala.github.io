<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Through-Wall Human Pose Estimation Using Radio Signals - DawsonWen的个人网站</title>
    <meta name="author"  content="DawsonWen">
    <meta name="description" content="Through-Wall Human Pose Estimation Using Radio Signals">
    <meta name="keywords"  content="论文阅读">
    <!-- Open Graph -->
    <meta property="og:title" content="Through-Wall Human Pose Estimation Using Radio Signals - DawsonWen的个人网站">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2020/11/05/rfpose.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="DawsonWen的个人网站">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB" class="post-tag">论文阅读</a>
          
        
      </div>
      <h1>Through-Wall Human Pose Estimation Using Radio Signals</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>郑之杰</span>
        <time class="post-meta-item" datetime="20-11-05"><i class="iconfont icon-date"></i>05 Nov 2020</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://pic.downk.cc/item/5fa35dd81cd1bbb86b45809e.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <blockquote>
  <p>RF-Pose：使用射频信号进行穿墙人体姿态估计.</p>
</blockquote>

<ul>
  <li>paper：Through-Wall Human Pose Estimation Using Radio Signals</li>
  <li>website：<a href="http://rfpose.csail.mit.edu/">link</a></li>
</ul>

<h1 id="0-abstract">0. Abstract</h1>
<p>本文提出了一种使用无线电信号<strong>(radio frequency，RF)</strong>穿过墙壁和遮挡进行人体姿态估计的方法<strong>RF-Pose</strong>。由于人类无法直接标注无线电信号，作者使用<strong>SOTA</strong>视觉模型进行<strong>跨模态监督(cross-modal supervision)</strong>。</p>

<p>在训练时，系统同步使用无线信号和视觉信号作为输入，使用视觉信号监督从无线信号中抽取姿态信息；测试时，网络只使用无线信号进行姿态估计。</p>

<h1 id="1-introduction">1. Introduction</h1>
<p>人体姿态估计是指通过估计关键点生成人体的$2D$或$3D$骨骼表示，现有的方法不能很好地解决遮挡问题。目前常用的方法是通过人体的可见部分假象地构造遮挡部分，但是由于人体是可变形的，构造很容易出现错误。当人体被完全遮挡（如人在墙壁后）这些方法会失效。</p>

<p>由于可见光会被墙壁和不透明物体遮挡，作者使用能够穿墙的<strong>WiFi</strong>范围内的射频信号。具体地使用比<strong>WiFi</strong>低一千倍的低功率无线信号。下图是该方法的结果展示。第一行表示采集的<strong>RGB</strong>图像，第二行表示模型提取得到的人体关键点的<strong>confidence map</strong>，第三行表示生成的$2D$骨骼。该方法也可以同时检测多个人。</p>

<p><img src="https://pic.downk.cc/item/5fa3777e1cd1bbb86b4b4a62.jpg" alt="" /></p>

<p>穿墙的人体姿态估计没有标签数据，人类也无法在无线信号上标注关键点。为解决这些问题，作者使用了<strong>跨模态监督(cross-modal supervision)</strong>。在训练时，在无线传感器上附加了一个网络摄像头，用于同步获得无线信号和视觉信号，并将视觉信号作为无线信号的监督。在测试时，只使用无线信号进行姿态估计。值得一提的是，训练时没有提供人体完全被遮挡的样本，测试时也可以检测出墙壁后的人体。</p>

<p>训练和测试数据都是从<strong>MIT</strong>校园内采集的。作者人工标注了$2000$张<strong>RGB</strong>图像作为测试集。对于可见场景，基于视觉的模型实现了$AP 68.8$，而本模型实现了$AP 62.4$；对于穿墙场景，本模型实现了$AP 58.1$。</p>

<p>作者还尝试从学习到的人体骨架中提取不同人的识别特征及其移动方式。作者收集了$100$人的$2s$行走信号，使用<strong>CNN</strong>识别每一个人。通过简单地观察基于<strong>RF</strong>的骨架是如何移动的，分类器获得了$83\%$的识别准确率。</p>

<h1 id="2-related-work">2. Related Work</h1>

<h3 id="a计算机视觉">（a）计算机视觉</h3>
<p>基于<strong>RGB</strong>图像的人体姿态估计包括<strong>Top-down</strong>方法和<strong>Bottom-up</strong>方法。<strong>Top-down</strong>方法首先检测图像中的每一个人体，再对每一个人体使用单人体的姿态估计方法检测关键点。<strong>Bottom-up</strong>方法先检测图像中的所有关键点，再将关键点划分到每一个人体。作者选择<strong>Bottom-up</strong>方法。</p>

<p><strong>跨模态学习(cross-modal learning)</strong>或者<strong>多模态学习(multi-modal learning)</strong>是指匹配不同的数据模态或者提供跨模态的补充信息。在本文中作者使用了跨模态的教师-学生网络，将<strong>RGB</strong>数据模态中的信息迁移到无线信号模态中。</p>

<h3 id="b无线系统-wireless-systems">（b）无线系统 Wireless Systems</h3>
<p>用于检测人体的无线信号可以分成两类。</p>
<ul>
  <li>第一类是<strong>高频信号</strong>（如毫米波、太赫兹信号），这些信号可以对人体表面进行准确地成像，但不能穿透墙壁或家具。</li>
  <li>第二类是<strong>低频信号</strong>（频率几<strong>GHz</strong>），能够实现穿墙检测。</li>
</ul>

<p>可以穿墙检测的系统可以分为<strong>device-based</strong>和<strong>device-free</strong>。</p>
<ul>
  <li><strong>device-based</strong>系统使用一些无线设备产生的信号定位人体，如使用手机中的<strong>Wi-Fi</strong>信号。这类系统需要将无线设备部署到人体的不同部位来跟踪检测。</li>
  <li><strong>device-free</strong>系统通过分析人体反射的无线电信号来工作，不需要人佩戴任何设备。但这类系统成像分辨率低，不同同时定位身体的多个部位。</li>
</ul>

<p>作者也调研了一些使用无线信号进行身份识别的模型。但它们对人的移动方式有很大的限制，不能从自由形式的步行中识别人。</p>

<h1 id="3-rf-signals-acquisition-and-properties">3. RF Signals Acquisition and Properties</h1>
<p>作者提出的模型需要发射低功率的射频信号并接收其反射。通常使用<strong>FMCW（调频连续波）</strong>和<strong>天线阵列</strong>等技术实现对不同目标反射信号的分离。<strong>FMCW</strong>根据反射对象的距离分离反射，而天线阵列根据其空间方向分离反射。</p>

<p>本文使用了具有两个天线阵列（<strong>vertical</strong>和<strong>horizontal</strong>）的无线电系统，产生两维的输入数据，如下图所示。其中水平热图是反射信号在平行于地面的平面上的投影，而垂直热图是反射信号在垂直于地面的平面上的投影；注意到每个像素值都是一个复数；系统每秒可以生成<strong>30</strong>对热图。</p>

<p><img src="https://pic.downk.cc/item/5fa3a8eb1cd1bbb86b56d59c.jpg" alt="" /></p>

<p>射频信号和常见的视觉数据相比，存在较大的差异，主要体现为：</p>
<ol>
  <li>穿墙的射频信号分辨率较低，通常只有十几或几十厘米，由<strong>FMCW</strong>信号的带宽和天线阵列的孔径决定。本实验中分辨率为$10cm$，天线的角分辨率是$15°$。</li>
  <li>当波长大于目标的表面粗糙度时会发生<strong>镜面反射(specularity)</strong>现象。本实验中信号的波长是$5cm$，会在人体表面发生镜面反射，每一次采集的无线图像可能会缺失身体的一部分。</li>
  <li>射频信号与视觉数据相比有不同的数据表示（复数）和不同的视角（水平和垂直投影）。</li>
</ol>

<h1 id="4-method">4. Method</h1>
<p><strong>RF-Pose</strong>模型结构如下图所示，<strong>teacher network</strong>提供跨模态的监督，<strong>student network</strong>实现姿态估计。</p>

<p><img src="https://pic.downk.cc/item/5fa3ad141cd1bbb86b57b896.jpg" alt="" /></p>

<h3 id="a-teacher-network">(a) Teacher Network</h3>

<p><strong>teacher network</strong>接收<strong>RGB</strong>图像作为输入，产生预测的关键点置信度映射；<strong>student network</strong>接收对应射频信号作为输入，学习该关键点映射。</p>

<p>作者使用<a href="">Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a>中提出的模型作为<strong>teacher network</strong>，<strong>student network</strong>预测人体的$14$个关键点：头部，颈部，肩部，肘部，手腕，臀部，膝盖和脚踝。</p>

<h3 id="b-student-network">(b) Student Network</h3>

<p><strong>student network</strong>采用了编码器-解码器结构，使用多个编码器对水平和垂直热图信息分别进行编码，将特征编码按通道连接后使用单个解码器预测关键点的置信度热图。编码器使用<strong>strided convolutional network</strong>，解码器使用<strong>fractionally strided convolutional network</strong>。</p>

<p>由于人体对射频信号是镜像的，从单张射频图像中很难估计人体的全部关键点（成像可能会损失部位信息）。作者使用了一系列帧作为<strong>student network</strong>的输入，网络一次接收多帧射频图像，并输入每个射频图像帧的姿态估计。使用<strong>时空卷积(spatiotemporal convolution)</strong>作为基本的组成单元。</p>

<p>编码器使用$100$帧作为输入，设置<strong>batch</strong>为$24$，使用$10$层$9 \times 5 \times 5$的时空卷积，每隔一层设置$1 \times 2 \times 2$的步长。每一层后使用<strong>BatchNorm</strong>和<strong>ReLU</strong>激活函数。</p>

<p>解码器使用$4$层$3 \times 6 \times 6$的时空卷积。前三层设置$1 \times \frac{1}{2} \times \frac{1}{2}$的步长，使用<strong>PReLU</strong>激活函数；最后一层设置$1 \times \frac{1}{4} \times \frac{1}{4}$的步长，使用<strong>Sigmoid</strong>激活函数。</p>

<h3 id="c-keypoint-association">(c) Keypoint Association</h3>
<p>获得关键点预测热图后，对每一帧分别进行处理。首先对其进行非极大值抑制，以获得候选关键点的离散峰。之后使用欧几里德距离作为两个候选关键点的权重，应用松弛方法获得预测骨骼。</p>

<h1 id="5-dataset">5. Dataset</h1>
<p>作者收集了无遮挡场景的数据作为训练集。具体地，在射频传感器上附加网络摄像头，同时捕捉射频信号和光学信号，两者之间的时延误差约为$7ms$。作者从$50$个环境收集了$50h$数据，单帧最大人数和平均人数分别为$14$人和$1.64$人。</p>

<p>作者收集了墙遮挡场景的数据作为测试集。具体地，建立$8$个摄像头的移动相机系统，标定后构造人体三维姿态，并将其投影到与射频传感器相同定位的相机视图上。单帧最大人数和平均人数分别为$3$人和$1.41$人。</p>

<h1 id="6-experiments">6. Experiments</h1>
<p>作者分析了一些估计失败的案例。通过实验发现，使用射频方法相对于使用光学方法（如<strong>OpenPose</strong>）进行姿态估计在两种情况下失败。第一是人体被金属物体遮挡，因为金属物体会阻断射频信号；第二是人群太过密集，射频信号的低分辨率会无法区分。</p>

<p><img src="https://pic.downk.cc/item/5fa4fb6e1cd1bbb86ba0cd83.jpg" alt="" /></p>

<p>作者使用<strong>guided back-propagation</strong>方法分析输入射频信号的哪些位置会对预测结果起到更重要的作用。实验发现，对于一张水平投影图像，网络将关注点放在两个人的位置而不是前面的墙。</p>

<p><img src="https://pic.downk.cc/item/5fa4fc711cd1bbb86ba13f43.jpg" alt="" /></p>

<p>作者通过实验证明输入使用一段视频帧而不是单帧会更好。下图是输入一段视频帧（$100$帧，约$3s$），网络对不同关键点的预测结果对输入帧的梯度响应，每帧的梯度响应取绝对值的和。作者发现右<strong>knee</strong>和右<strong>ankle</strong>的响应是高度相关的，而左<strong>wrist</strong>和左<strong>elbow</strong>之间存在延迟。</p>

<p><img src="https://pic.downk.cc/item/5fa4fc821cd1bbb86ba145a1.jpg" alt="" /></p>

<p>当前的工作仍然存在一些问题，列举如下：</p>
<ol>
  <li>无法解决人与人的遮挡（射频信号不能穿过人体）；</li>
  <li>系统的工作距离取决于传输功率，本文的工作距离约$40$ <strong>feet</strong>；</li>
  <li>当前的系统没有分析过于复杂的人类动作。</li>
</ol>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="https://avatars.githubusercontent.com/u/46283762?v=4&size=64" alt="">
      </div>
      <div class="author-name" rel="author">DawsonWen</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/Sologala" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2020/11/06/nonlocal.html" class="read-next-link"></a>
        <section>
          <span>Non-Local Neural Networks</span>
          <p>  非局部神经网络.</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://pic.imgdb.cn/item/63fc1560f144a010074ad1cb.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2020/11/04/cmptse.html" class="read-next-link"></a>
          <section>
            <span>Competitive Inner-Imaging Squeeze and Excitation for Residual Network</span>
            <p>  残差网络的竞争性内部图像通道注意力机制.</p>
          </section>
          
          <div class="filter"></div>
          <img src="https://pic.imgdb.cn/item/63c00d76be43e0d30e587048.jpg" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <!-- <footer class="g-footer">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=800&t=m&d=WWuzUTmOt8V9vdtIQd5uqrEcKsRg4IiPuy9gg21CQO8'></script>
  <section>DawsonWen的个人网站 ©
  
  
    2020
    -
  
  2024
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>
 -->

  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
